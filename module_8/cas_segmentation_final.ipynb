{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ikboljon.sobirov/miniconda3/envs/lumen/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai import transforms\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Activations,\n",
    ")\n",
    "\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.utils.enums import MetricReduction\n",
    "from monai.networks.nets import SwinUNETR, SegResNet, UNet\n",
    "from monai import data\n",
    "from monai.data import decollate_batch\n",
    "from functools import partial\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datafold_read(datalist, basedir, fold=0, key=\"training\"):\n",
    "    with open(datalist) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    json_data = json_data[key]\n",
    "\n",
    "    for d in json_data:\n",
    "        for k in d:\n",
    "            if isinstance(d[k], list):\n",
    "                d[k] = [os.path.join(basedir, iv) for iv in d[k]]\n",
    "            elif isinstance(d[k], str):\n",
    "                d[k] = os.path.join(basedir, d[k]) if len(d[k]) > 0 else d[k]\n",
    "\n",
    "    tr = []\n",
    "    val = []\n",
    "    for d in json_data:\n",
    "        if \"fold\" in d and d[\"fold\"] == fold:\n",
    "            val.append(d)\n",
    "        else:\n",
    "            tr.append(d)\n",
    "\n",
    "    return tr, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/ikboljon.sobirov/data/fs1_research/Ikboljon.Sobirov/imagecas/imagecas/resampled_space/'\n",
    "json_file = '/home/ikboljon.sobirov/data/nas/ikboljon.sobirov/image_cas/chuqur_organish_asoslari/module_8/train_data.json'\n",
    "fold = 1\n",
    "roi = (96, 96, 96)\n",
    "batch_size = 1\n",
    "num_crop_samples=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: 160, Validation files: 40\n"
     ]
    }
   ],
   "source": [
    "train_files, validation_files = datafold_read(datalist=json_file, basedir=data_dir, fold=fold)\n",
    "print(f\"Train files: {len(train_files)}, Validation files: {len(validation_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_norm = (img - mean)/std\n",
    "# min_max = (img - min)/(max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"mask\"], ensure_channel_first=True),\n",
    "        transforms.SpatialPadd(keys=[\"image\", \"mask\"], spatial_size=roi),\n",
    "        transforms.RandCropByPosNegLabeld(keys=[\"image\", \"mask\"], \n",
    "                                        label_key=\"mask\",\n",
    "                                        spatial_size=roi,\n",
    "                                        num_samples=num_crop_samples,\n",
    "                                        image_key=\"image\",),\n",
    "        # transforms.CropForegroundd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     source_key=\"image\",\n",
    "        #     k_divisible=[roi[0], roi[1], roi[2]],\n",
    "        # ),\n",
    "        # transforms.RandSpatialCropd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     roi_size=[roi[0], roi[1], roi[2]],\n",
    "        #     random_size=False,\n",
    "        # ),\n",
    "        # transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        # transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        # transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        # transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        # transforms.RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "        # transforms.RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "    ]\n",
    ")\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"mask\"], ensure_channel_first=True),\n",
    "        transforms.SpatialPadd(keys=[\"image\", \"mask\"], spatial_size=roi),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_ds = data.Dataset(data=train_files, transform=train_transform)\n",
    "\n",
    "train_loader = data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_ds = data.Dataset(data=validation_files, transform=val_transform)\n",
    "val_loader = data.DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 96, 96, 96])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5d0391aa90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a['mask'].cpu().detach()[0, 0, :, :, 50], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple segresnet\n",
    "model = SegResNet(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    init_filters=16,\n",
    ")\n",
    "\n",
    "# monster segresnet\n",
    "# model = SegResNet(\n",
    "#                 in_channels=1, \n",
    "#                 out_channels=1, \n",
    "#                 init_filters=32,\n",
    "#                 norm='BATCH', \n",
    "#                 blocks_down=(1,2,2,4,4,4), \n",
    "#                 blocks_up=(1,1,1,1,1), \n",
    "#                 upsample_mode='deconv',)\n",
    "\n",
    "# swinunetr\n",
    "# model = SwinUNETR(\n",
    "#                 img_size=roi,\n",
    "#                 in_channels=4,\n",
    "#                 out_channels=3,\n",
    "#                 feature_size=48,\n",
    "#                 drop_rate=0.0,\n",
    "#                 attn_drop_rate=0.0,\n",
    "#                 dropout_path_rate=0.0,\n",
    "#                 use_checkpoint=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=False, sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=False, reduction=MetricReduction.MEAN_BATCH, get_not_nans=True)\n",
    "\n",
    "max_epochs = 10\n",
    "val_interval = 1\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "sw_batch_size = 4\n",
    "infer_overlap = 0.5\n",
    "\n",
    "\n",
    "model_inferer = partial(\n",
    "    sliding_window_inference,\n",
    "    roi_size=[roi[0], roi[1], roi[2]],\n",
    "    sw_batch_size=sw_batch_size,\n",
    "    predictor=model,\n",
    "    overlap=infer_overlap,\n",
    ")\n",
    "\n",
    "# post_sigmoid = Activations(sigmoid=True)\n",
    "# post_pred = AsDiscrete(argmax=False, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(input, target):\n",
    "    axes = tuple(range(1, input.dim()))\n",
    "    bin_input = (input > 0.5).float()\n",
    "\n",
    "    intersect = (bin_input * target).sum(dim=axes)\n",
    "    union = bin_input.sum(dim=axes) + target.sum(dim=axes)\n",
    "    score = 2 * intersect / (union + 1e-5)\n",
    "\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/10\n",
      "1/160, train_loss: 0.9935\n",
      "2/160, train_loss: 0.9895\n",
      "3/160, train_loss: 0.9920\n",
      "4/160, train_loss: 0.9935\n",
      "5/160, train_loss: 0.9927\n",
      "6/160, train_loss: 0.9926\n",
      "7/160, train_loss: 0.9875\n",
      "8/160, train_loss: 0.9869\n",
      "9/160, train_loss: 0.9921\n",
      "10/160, train_loss: 0.9914\n",
      "11/160, train_loss: 0.9935\n",
      "12/160, train_loss: 0.9934\n",
      "13/160, train_loss: 0.9942\n",
      "14/160, train_loss: 0.9882\n",
      "15/160, train_loss: 0.9893\n",
      "16/160, train_loss: 0.9905\n",
      "17/160, train_loss: 0.9878\n",
      "18/160, train_loss: 0.9869\n",
      "19/160, train_loss: 0.9928\n",
      "20/160, train_loss: 0.9902\n",
      "21/160, train_loss: 0.9893\n",
      "22/160, train_loss: 0.9915\n",
      "23/160, train_loss: 0.9926\n",
      "24/160, train_loss: 0.9868\n",
      "25/160, train_loss: 0.9884\n",
      "26/160, train_loss: 0.9902\n",
      "27/160, train_loss: 0.9883\n",
      "28/160, train_loss: 0.9872\n",
      "29/160, train_loss: 0.9899\n",
      "30/160, train_loss: 0.9924\n",
      "31/160, train_loss: 0.9841\n",
      "32/160, train_loss: 0.9887\n",
      "33/160, train_loss: 0.9842\n",
      "34/160, train_loss: 0.9921\n",
      "35/160, train_loss: 0.9903\n",
      "36/160, train_loss: 0.9866\n",
      "37/160, train_loss: 0.9800\n",
      "38/160, train_loss: 0.9926\n",
      "39/160, train_loss: 0.9924\n",
      "40/160, train_loss: 0.9876\n",
      "41/160, train_loss: 0.9913\n",
      "42/160, train_loss: 0.9898\n",
      "43/160, train_loss: 0.9897\n",
      "44/160, train_loss: 0.9814\n",
      "45/160, train_loss: 0.9845\n",
      "46/160, train_loss: 0.9902\n",
      "47/160, train_loss: 0.9789\n",
      "48/160, train_loss: 0.9907\n",
      "49/160, train_loss: 0.9895\n",
      "50/160, train_loss: 0.9826\n",
      "51/160, train_loss: 0.9821\n",
      "52/160, train_loss: 0.9740\n",
      "53/160, train_loss: 0.9822\n",
      "54/160, train_loss: 0.9899\n",
      "55/160, train_loss: 0.9765\n",
      "56/160, train_loss: 0.9852\n",
      "57/160, train_loss: 0.9906\n",
      "58/160, train_loss: 0.9871\n",
      "59/160, train_loss: 0.9859\n",
      "60/160, train_loss: 0.9773\n",
      "61/160, train_loss: 0.9877\n",
      "62/160, train_loss: 0.9696\n",
      "63/160, train_loss: 0.9752\n",
      "64/160, train_loss: 0.9854\n",
      "65/160, train_loss: 0.9659\n",
      "66/160, train_loss: 0.9734\n",
      "67/160, train_loss: 0.9662\n",
      "68/160, train_loss: 0.9724\n",
      "69/160, train_loss: 0.9619\n",
      "70/160, train_loss: 0.9784\n",
      "71/160, train_loss: 0.9826\n",
      "72/160, train_loss: 0.9833\n",
      "73/160, train_loss: 0.9722\n",
      "74/160, train_loss: 0.9702\n",
      "75/160, train_loss: 0.9650\n",
      "76/160, train_loss: 0.9662\n",
      "77/160, train_loss: 0.9768\n",
      "78/160, train_loss: 0.9757\n",
      "79/160, train_loss: 0.9747\n",
      "80/160, train_loss: 0.9758\n",
      "81/160, train_loss: 0.9631\n",
      "82/160, train_loss: 0.9647\n",
      "83/160, train_loss: 0.9801\n",
      "84/160, train_loss: 0.9680\n",
      "85/160, train_loss: 0.9683\n",
      "86/160, train_loss: 0.9732\n",
      "87/160, train_loss: 0.9766\n",
      "88/160, train_loss: 0.9634\n",
      "89/160, train_loss: 0.9783\n",
      "90/160, train_loss: 0.9591\n",
      "91/160, train_loss: 0.9619\n",
      "92/160, train_loss: 0.9640\n",
      "93/160, train_loss: 0.9558\n",
      "94/160, train_loss: 0.9592\n",
      "95/160, train_loss: 0.9525\n",
      "96/160, train_loss: 0.9584\n",
      "97/160, train_loss: 0.9348\n",
      "98/160, train_loss: 0.9713\n",
      "99/160, train_loss: 0.9522\n",
      "100/160, train_loss: 0.9431\n",
      "101/160, train_loss: 0.9699\n",
      "102/160, train_loss: 0.9215\n",
      "103/160, train_loss: 0.9593\n",
      "104/160, train_loss: 0.9697\n",
      "105/160, train_loss: 0.9578\n",
      "106/160, train_loss: 0.9536\n",
      "107/160, train_loss: 0.9586\n",
      "108/160, train_loss: 0.9477\n",
      "109/160, train_loss: 0.9546\n",
      "110/160, train_loss: 0.9129\n",
      "111/160, train_loss: 0.9536\n",
      "112/160, train_loss: 0.9345\n",
      "113/160, train_loss: 0.9413\n",
      "114/160, train_loss: 0.9098\n",
      "115/160, train_loss: 0.9242\n",
      "116/160, train_loss: 0.9620\n",
      "117/160, train_loss: 0.9551\n",
      "118/160, train_loss: 0.9457\n",
      "119/160, train_loss: 0.9102\n",
      "120/160, train_loss: 0.9070\n",
      "121/160, train_loss: 0.9086\n",
      "122/160, train_loss: 0.9657\n",
      "123/160, train_loss: 0.9311\n",
      "124/160, train_loss: 0.9393\n",
      "125/160, train_loss: 0.9145\n",
      "126/160, train_loss: 0.9271\n",
      "127/160, train_loss: 0.9259\n",
      "128/160, train_loss: 0.9544\n",
      "129/160, train_loss: 0.9254\n",
      "130/160, train_loss: 0.8734\n",
      "131/160, train_loss: 0.9141\n",
      "132/160, train_loss: 0.9255\n",
      "133/160, train_loss: 0.9302\n",
      "134/160, train_loss: 0.9101\n",
      "135/160, train_loss: 0.9179\n",
      "136/160, train_loss: 0.9692\n",
      "137/160, train_loss: 0.8552\n",
      "138/160, train_loss: 0.9092\n",
      "139/160, train_loss: 0.9176\n",
      "140/160, train_loss: 0.8994\n",
      "141/160, train_loss: 0.8692\n",
      "142/160, train_loss: 0.8846\n",
      "143/160, train_loss: 0.9014\n",
      "144/160, train_loss: 0.8971\n",
      "145/160, train_loss: 0.9023\n",
      "146/160, train_loss: 0.8824\n",
      "147/160, train_loss: 0.8724\n",
      "148/160, train_loss: 0.9198\n",
      "149/160, train_loss: 0.8997\n",
      "150/160, train_loss: 0.8860\n",
      "151/160, train_loss: 0.8877\n",
      "152/160, train_loss: 0.8456\n",
      "153/160, train_loss: 0.8913\n",
      "154/160, train_loss: 0.8929\n",
      "155/160, train_loss: 0.8786\n",
      "156/160, train_loss: 0.8593\n",
      "157/160, train_loss: 0.8865\n",
      "158/160, train_loss: 0.8282\n",
      "159/160, train_loss: 0.8872\n",
      "160/160, train_loss: 0.8742\n",
      "Epoch 0/10 159/160 loss: 0.9558 time 84.57s\n",
      "0/40 dice: 0.3292\n",
      "1/40 dice: 0.1751\n",
      "2/40 dice: 0.3379\n",
      "3/40 dice: 0.1831\n",
      "4/40 dice: 0.2378\n",
      "5/40 dice: 0.3665\n",
      "6/40 dice: 0.2352\n",
      "7/40 dice: 0.2598\n",
      "8/40 dice: 0.3734\n",
      "9/40 dice: 0.3198\n",
      "10/40 dice: 0.1725\n",
      "11/40 dice: 0.3133\n",
      "12/40 dice: 0.2797\n",
      "13/40 dice: 0.4126\n",
      "14/40 dice: 0.2935\n",
      "15/40 dice: 0.2596\n",
      "16/40 dice: 0.2723\n",
      "17/40 dice: 0.3292\n",
      "18/40 dice: 0.2122\n",
      "19/40 dice: 0.2502\n",
      "20/40 dice: 0.2603\n",
      "21/40 dice: 0.2530\n",
      "22/40 dice: 0.2115\n",
      "23/40 dice: 0.2857\n",
      "24/40 dice: 0.2976\n",
      "25/40 dice: 0.2419\n",
      "26/40 dice: 0.3188\n",
      "27/40 dice: 0.2847\n",
      "28/40 dice: 0.3651\n",
      "29/40 dice: 0.2939\n",
      "30/40 dice: 0.3540\n",
      "31/40 dice: 0.2500\n",
      "32/40 dice: 0.3824\n",
      "33/40 dice: 0.2733\n",
      "34/40 dice: 0.2369\n",
      "35/40 dice: 0.2712\n",
      "36/40 dice: 0.2452\n",
      "37/40 dice: 0.1899\n",
      "38/40 dice: 0.2334\n",
      "39/40 dice: 0.2337\n",
      "saved new best metric model\n",
      "current epoch: 1 current mean dice: 0.2774 best mean dice: 0.2774 at epoch: 1\n",
      "----------\n",
      "epoch 2/10\n",
      "1/160, train_loss: 0.8905\n",
      "2/160, train_loss: 0.8537\n",
      "3/160, train_loss: 0.7658\n",
      "4/160, train_loss: 0.8099\n",
      "5/160, train_loss: 0.8227\n",
      "6/160, train_loss: 0.8275\n",
      "7/160, train_loss: 0.8746\n",
      "8/160, train_loss: 0.7885\n",
      "9/160, train_loss: 0.7880\n",
      "10/160, train_loss: 0.7053\n",
      "11/160, train_loss: 0.9251\n",
      "12/160, train_loss: 0.8874\n",
      "13/160, train_loss: 0.8574\n",
      "14/160, train_loss: 0.7299\n",
      "15/160, train_loss: 0.8135\n",
      "16/160, train_loss: 0.7844\n",
      "17/160, train_loss: 0.8339\n",
      "18/160, train_loss: 0.7677\n",
      "19/160, train_loss: 0.8703\n",
      "20/160, train_loss: 0.8084\n",
      "21/160, train_loss: 0.7769\n",
      "22/160, train_loss: 0.7696\n",
      "23/160, train_loss: 0.6861\n",
      "24/160, train_loss: 0.7413\n",
      "25/160, train_loss: 0.7087\n",
      "26/160, train_loss: 0.8446\n",
      "27/160, train_loss: 0.7409\n",
      "28/160, train_loss: 0.8020\n",
      "29/160, train_loss: 0.7020\n",
      "30/160, train_loss: 0.7216\n",
      "31/160, train_loss: 0.7596\n",
      "32/160, train_loss: 0.7097\n",
      "33/160, train_loss: 0.7906\n",
      "34/160, train_loss: 0.6495\n",
      "35/160, train_loss: 0.8098\n",
      "36/160, train_loss: 0.7277\n",
      "37/160, train_loss: 0.7573\n",
      "38/160, train_loss: 0.7040\n",
      "39/160, train_loss: 0.6862\n",
      "40/160, train_loss: 0.7678\n",
      "41/160, train_loss: 0.6650\n",
      "42/160, train_loss: 0.7454\n",
      "43/160, train_loss: 0.6642\n",
      "44/160, train_loss: 0.6733\n",
      "45/160, train_loss: 0.7257\n",
      "46/160, train_loss: 0.7043\n",
      "47/160, train_loss: 0.6224\n",
      "48/160, train_loss: 0.6941\n",
      "49/160, train_loss: 0.6589\n",
      "50/160, train_loss: 0.7270\n",
      "51/160, train_loss: 0.6599\n",
      "52/160, train_loss: 0.6831\n",
      "53/160, train_loss: 0.6594\n",
      "54/160, train_loss: 0.6732\n",
      "55/160, train_loss: 0.6122\n",
      "56/160, train_loss: 0.6139\n",
      "57/160, train_loss: 0.5956\n",
      "58/160, train_loss: 0.7408\n",
      "59/160, train_loss: 0.7315\n",
      "60/160, train_loss: 0.6872\n",
      "61/160, train_loss: 0.5722\n",
      "62/160, train_loss: 0.5556\n",
      "63/160, train_loss: 0.6735\n",
      "64/160, train_loss: 0.7194\n",
      "65/160, train_loss: 0.5914\n",
      "66/160, train_loss: 0.5794\n",
      "67/160, train_loss: 0.5485\n",
      "68/160, train_loss: 0.6688\n",
      "69/160, train_loss: 0.6515\n",
      "70/160, train_loss: 0.6468\n",
      "71/160, train_loss: 0.5753\n",
      "72/160, train_loss: 0.4778\n",
      "73/160, train_loss: 0.7204\n",
      "74/160, train_loss: 0.5450\n",
      "75/160, train_loss: 0.7480\n",
      "76/160, train_loss: 0.6114\n",
      "77/160, train_loss: 0.4518\n",
      "78/160, train_loss: 0.6987\n",
      "79/160, train_loss: 0.5692\n",
      "80/160, train_loss: 0.6714\n",
      "81/160, train_loss: 0.5154\n",
      "82/160, train_loss: 0.6784\n",
      "83/160, train_loss: 0.4403\n",
      "84/160, train_loss: 0.5813\n",
      "85/160, train_loss: 0.6467\n",
      "86/160, train_loss: 0.5117\n",
      "87/160, train_loss: 0.6095\n",
      "88/160, train_loss: 0.5588\n",
      "89/160, train_loss: 0.6050\n",
      "90/160, train_loss: 0.4476\n",
      "91/160, train_loss: 0.4470\n",
      "92/160, train_loss: 0.5063\n",
      "93/160, train_loss: 0.6218\n",
      "94/160, train_loss: 0.4246\n",
      "95/160, train_loss: 0.4464\n",
      "96/160, train_loss: 0.5134\n",
      "97/160, train_loss: 0.5128\n",
      "98/160, train_loss: 0.6127\n",
      "99/160, train_loss: 0.6559\n",
      "100/160, train_loss: 0.4633\n",
      "101/160, train_loss: 0.5605\n",
      "102/160, train_loss: 0.3689\n",
      "103/160, train_loss: 0.5588\n",
      "104/160, train_loss: 0.5812\n",
      "105/160, train_loss: 0.4609\n",
      "106/160, train_loss: 0.3707\n",
      "107/160, train_loss: 0.5442\n",
      "108/160, train_loss: 0.4510\n",
      "109/160, train_loss: 0.6296\n",
      "110/160, train_loss: 0.5261\n",
      "111/160, train_loss: 0.5506\n",
      "112/160, train_loss: 0.4332\n",
      "113/160, train_loss: 0.5339\n",
      "114/160, train_loss: 0.5910\n",
      "115/160, train_loss: 0.4661\n",
      "116/160, train_loss: 0.6450\n",
      "117/160, train_loss: 0.4776\n",
      "118/160, train_loss: 0.4904\n",
      "119/160, train_loss: 0.7383\n",
      "120/160, train_loss: 0.4054\n",
      "121/160, train_loss: 0.5019\n",
      "122/160, train_loss: 0.5350\n",
      "123/160, train_loss: 0.4595\n",
      "124/160, train_loss: 0.4609\n",
      "125/160, train_loss: 0.6004\n",
      "126/160, train_loss: 0.4289\n",
      "127/160, train_loss: 0.4593\n",
      "128/160, train_loss: 0.5527\n",
      "129/160, train_loss: 0.4087\n",
      "130/160, train_loss: 0.5708\n",
      "131/160, train_loss: 0.5394\n",
      "132/160, train_loss: 0.4735\n",
      "133/160, train_loss: 0.4648\n",
      "134/160, train_loss: 0.5225\n",
      "135/160, train_loss: 0.5522\n",
      "136/160, train_loss: 0.4873\n",
      "137/160, train_loss: 0.5333\n",
      "138/160, train_loss: 0.5357\n",
      "139/160, train_loss: 0.3746\n",
      "140/160, train_loss: 0.5130\n",
      "141/160, train_loss: 0.4572\n",
      "142/160, train_loss: 0.2952\n",
      "143/160, train_loss: 0.4090\n",
      "144/160, train_loss: 0.3561\n",
      "145/160, train_loss: 0.5366\n",
      "146/160, train_loss: 0.4471\n",
      "147/160, train_loss: 0.3576\n",
      "148/160, train_loss: 0.6011\n",
      "149/160, train_loss: 0.6361\n",
      "150/160, train_loss: 0.4849\n",
      "151/160, train_loss: 0.4794\n",
      "152/160, train_loss: 0.5310\n",
      "153/160, train_loss: 0.6245\n",
      "154/160, train_loss: 0.5454\n",
      "155/160, train_loss: 0.4321\n",
      "156/160, train_loss: 0.5616\n",
      "157/160, train_loss: 0.4057\n",
      "158/160, train_loss: 0.6976\n",
      "159/160, train_loss: 0.4722\n",
      "160/160, train_loss: 0.5092\n",
      "Epoch 1/10 159/160 loss: 0.6129 time 72.45s\n",
      "0/40 dice: 0.6059\n",
      "1/40 dice: 0.3725\n",
      "2/40 dice: 0.4745\n",
      "3/40 dice: 0.3902\n",
      "4/40 dice: 0.4498\n",
      "5/40 dice: 0.5990\n",
      "6/40 dice: 0.4179\n",
      "7/40 dice: 0.4934\n",
      "8/40 dice: 0.4832\n",
      "9/40 dice: 0.6130\n",
      "10/40 dice: 0.4114\n",
      "11/40 dice: 0.5636\n",
      "12/40 dice: 0.4088\n",
      "13/40 dice: 0.5840\n",
      "14/40 dice: 0.4601\n",
      "15/40 dice: 0.4421\n",
      "16/40 dice: 0.4970\n",
      "17/40 dice: 0.5372\n",
      "18/40 dice: 0.3820\n",
      "19/40 dice: 0.4892\n",
      "20/40 dice: 0.5151\n",
      "21/40 dice: 0.4987\n",
      "22/40 dice: 0.3939\n",
      "23/40 dice: 0.5049\n",
      "24/40 dice: 0.5321\n",
      "25/40 dice: 0.4196\n",
      "26/40 dice: 0.6170\n",
      "27/40 dice: 0.5070\n",
      "28/40 dice: 0.6069\n",
      "29/40 dice: 0.5454\n",
      "30/40 dice: 0.5938\n",
      "31/40 dice: 0.4360\n",
      "32/40 dice: 0.5341\n",
      "33/40 dice: 0.4919\n",
      "34/40 dice: 0.5112\n",
      "35/40 dice: 0.6202\n",
      "36/40 dice: 0.4219\n",
      "37/40 dice: 0.3445\n",
      "38/40 dice: 0.4810\n",
      "39/40 dice: 0.4267\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.4919 best mean dice: 0.4919 at epoch: 2\n",
      "----------\n",
      "epoch 3/10\n",
      "1/160, train_loss: 0.4725\n",
      "2/160, train_loss: 0.5267\n",
      "3/160, train_loss: 0.3925\n",
      "4/160, train_loss: 0.4981\n",
      "5/160, train_loss: 0.3786\n",
      "6/160, train_loss: 0.5273\n",
      "7/160, train_loss: 0.5289\n",
      "8/160, train_loss: 0.4773\n",
      "9/160, train_loss: 0.6039\n",
      "10/160, train_loss: 0.4443\n",
      "11/160, train_loss: 0.6069\n",
      "12/160, train_loss: 0.5809\n",
      "13/160, train_loss: 0.4505\n",
      "14/160, train_loss: 0.5692\n",
      "15/160, train_loss: 0.4920\n",
      "16/160, train_loss: 0.6118\n",
      "17/160, train_loss: 0.4704\n",
      "18/160, train_loss: 0.4481\n",
      "19/160, train_loss: 0.3888\n",
      "20/160, train_loss: 0.4125\n",
      "21/160, train_loss: 0.4038\n",
      "22/160, train_loss: 0.5214\n",
      "23/160, train_loss: 0.6967\n",
      "24/160, train_loss: 0.3380\n",
      "25/160, train_loss: 0.5260\n",
      "26/160, train_loss: 0.4118\n",
      "27/160, train_loss: 0.3450\n",
      "28/160, train_loss: 0.4919\n",
      "29/160, train_loss: 0.6128\n",
      "30/160, train_loss: 0.2833\n",
      "31/160, train_loss: 0.5895\n",
      "32/160, train_loss: 0.2973\n",
      "33/160, train_loss: 0.3937\n",
      "34/160, train_loss: 0.5963\n",
      "35/160, train_loss: 0.4516\n",
      "36/160, train_loss: 0.4161\n",
      "37/160, train_loss: 0.5288\n",
      "38/160, train_loss: 0.6436\n",
      "39/160, train_loss: 0.5713\n",
      "40/160, train_loss: 0.4901\n",
      "41/160, train_loss: 0.3867\n",
      "42/160, train_loss: 0.4331\n",
      "43/160, train_loss: 0.4950\n",
      "44/160, train_loss: 0.5399\n",
      "45/160, train_loss: 0.4056\n",
      "46/160, train_loss: 0.3489\n",
      "47/160, train_loss: 0.3930\n",
      "48/160, train_loss: 0.3730\n",
      "49/160, train_loss: 0.4516\n",
      "50/160, train_loss: 0.4253\n",
      "51/160, train_loss: 0.3125\n",
      "52/160, train_loss: 0.6075\n",
      "53/160, train_loss: 0.3356\n",
      "54/160, train_loss: 0.4150\n",
      "55/160, train_loss: 0.3549\n",
      "56/160, train_loss: 0.4106\n",
      "57/160, train_loss: 0.3981\n",
      "58/160, train_loss: 0.3430\n",
      "59/160, train_loss: 0.3698\n",
      "60/160, train_loss: 0.5239\n",
      "61/160, train_loss: 0.3268\n",
      "62/160, train_loss: 0.4711\n",
      "63/160, train_loss: 0.3955\n",
      "64/160, train_loss: 0.4585\n",
      "65/160, train_loss: 0.4342\n",
      "66/160, train_loss: 0.4206\n",
      "67/160, train_loss: 0.4512\n",
      "68/160, train_loss: 0.4044\n",
      "69/160, train_loss: 0.3716\n",
      "70/160, train_loss: 0.4601\n",
      "71/160, train_loss: 0.3789\n",
      "72/160, train_loss: 0.3650\n",
      "73/160, train_loss: 0.4500\n",
      "74/160, train_loss: 0.3433\n",
      "75/160, train_loss: 0.3037\n",
      "76/160, train_loss: 0.4965\n",
      "77/160, train_loss: 0.3145\n",
      "78/160, train_loss: 0.5208\n",
      "79/160, train_loss: 0.5601\n",
      "80/160, train_loss: 0.4252\n",
      "81/160, train_loss: 0.3361\n",
      "82/160, train_loss: 0.2927\n",
      "83/160, train_loss: 0.5594\n",
      "84/160, train_loss: 0.4294\n",
      "85/160, train_loss: 0.3820\n",
      "86/160, train_loss: 0.4613\n",
      "87/160, train_loss: 0.3226\n",
      "88/160, train_loss: 0.3263\n",
      "89/160, train_loss: 0.4521\n",
      "90/160, train_loss: 0.4809\n",
      "91/160, train_loss: 0.4514\n",
      "92/160, train_loss: 0.3616\n",
      "93/160, train_loss: 0.3108\n",
      "94/160, train_loss: 0.5408\n",
      "95/160, train_loss: 0.3613\n",
      "96/160, train_loss: 0.3445\n",
      "97/160, train_loss: 0.4539\n",
      "98/160, train_loss: 0.4913\n",
      "99/160, train_loss: 0.5235\n",
      "100/160, train_loss: 0.2910\n",
      "101/160, train_loss: 0.4398\n",
      "102/160, train_loss: 0.4190\n",
      "103/160, train_loss: 0.3352\n",
      "104/160, train_loss: 0.3271\n",
      "105/160, train_loss: 0.3839\n",
      "106/160, train_loss: 0.4326\n",
      "107/160, train_loss: 0.3433\n",
      "108/160, train_loss: 0.3398\n",
      "109/160, train_loss: 0.4138\n",
      "110/160, train_loss: 0.2963\n",
      "111/160, train_loss: 0.4335\n",
      "112/160, train_loss: 0.4115\n",
      "113/160, train_loss: 0.3875\n",
      "114/160, train_loss: 0.4154\n",
      "115/160, train_loss: 0.4650\n",
      "116/160, train_loss: 0.3725\n",
      "117/160, train_loss: 0.4052\n",
      "118/160, train_loss: 0.3119\n",
      "119/160, train_loss: 0.3121\n",
      "120/160, train_loss: 0.4925\n",
      "121/160, train_loss: 0.4148\n",
      "122/160, train_loss: 0.5116\n",
      "123/160, train_loss: 0.3666\n",
      "124/160, train_loss: 0.4081\n",
      "125/160, train_loss: 0.4756\n",
      "126/160, train_loss: 0.4857\n",
      "127/160, train_loss: 0.3632\n",
      "128/160, train_loss: 0.3573\n",
      "129/160, train_loss: 0.4132\n",
      "130/160, train_loss: 0.3147\n",
      "131/160, train_loss: 0.3628\n",
      "132/160, train_loss: 0.4510\n",
      "133/160, train_loss: 0.4588\n",
      "134/160, train_loss: 0.4543\n",
      "135/160, train_loss: 0.4021\n",
      "136/160, train_loss: 0.3238\n",
      "137/160, train_loss: 0.3319\n",
      "138/160, train_loss: 0.4582\n",
      "139/160, train_loss: 0.3544\n",
      "140/160, train_loss: 0.3336\n",
      "141/160, train_loss: 0.3948\n",
      "142/160, train_loss: 0.4392\n",
      "143/160, train_loss: 0.3954\n",
      "144/160, train_loss: 0.4524\n",
      "145/160, train_loss: 0.3962\n",
      "146/160, train_loss: 0.4705\n",
      "147/160, train_loss: 0.2859\n",
      "148/160, train_loss: 0.4174\n",
      "149/160, train_loss: 0.3295\n",
      "150/160, train_loss: 0.3688\n",
      "151/160, train_loss: 0.3359\n",
      "152/160, train_loss: 0.3786\n",
      "153/160, train_loss: 0.2632\n",
      "154/160, train_loss: 0.4601\n",
      "155/160, train_loss: 0.4856\n",
      "156/160, train_loss: 0.3467\n",
      "157/160, train_loss: 0.3926\n",
      "158/160, train_loss: 0.3339\n",
      "159/160, train_loss: 0.4836\n",
      "160/160, train_loss: 0.3557\n",
      "Epoch 2/10 159/160 loss: 0.4244 time 72.70s\n",
      "0/40 dice: 0.6661\n",
      "1/40 dice: 0.5563\n",
      "2/40 dice: 0.5842\n",
      "3/40 dice: 0.6114\n",
      "4/40 dice: 0.6231\n",
      "5/40 dice: 0.6955\n",
      "6/40 dice: 0.6885\n",
      "7/40 dice: 0.6275\n",
      "8/40 dice: 0.6275\n",
      "9/40 dice: 0.6765\n",
      "10/40 dice: 0.5529\n",
      "11/40 dice: 0.7052\n",
      "12/40 dice: 0.4836\n",
      "13/40 dice: 0.6022\n",
      "14/40 dice: 0.6059\n",
      "15/40 dice: 0.6336\n",
      "16/40 dice: 0.6394\n",
      "17/40 dice: 0.6284\n",
      "18/40 dice: 0.5867\n",
      "19/40 dice: 0.5792\n",
      "20/40 dice: 0.6182\n",
      "21/40 dice: 0.5659\n",
      "22/40 dice: 0.4521\n",
      "23/40 dice: 0.6542\n",
      "24/40 dice: 0.6661\n",
      "25/40 dice: 0.5752\n",
      "26/40 dice: 0.6801\n",
      "27/40 dice: 0.6634\n",
      "28/40 dice: 0.7168\n",
      "29/40 dice: 0.6539\n",
      "30/40 dice: 0.6353\n",
      "31/40 dice: 0.6010\n",
      "32/40 dice: 0.5543\n",
      "33/40 dice: 0.6293\n",
      "34/40 dice: 0.5966\n",
      "35/40 dice: 0.6318\n",
      "36/40 dice: 0.5677\n",
      "37/40 dice: 0.5921\n",
      "38/40 dice: 0.6550\n",
      "39/40 dice: 0.5776\n",
      "saved new best metric model\n",
      "current epoch: 3 current mean dice: 0.6165 best mean dice: 0.6165 at epoch: 3\n",
      "----------\n",
      "epoch 4/10\n",
      "1/160, train_loss: 0.3930\n",
      "2/160, train_loss: 0.3930\n",
      "3/160, train_loss: 0.2560\n",
      "4/160, train_loss: 0.4793\n",
      "5/160, train_loss: 0.4000\n",
      "6/160, train_loss: 0.3344\n",
      "7/160, train_loss: 0.2643\n",
      "8/160, train_loss: 0.3444\n",
      "9/160, train_loss: 0.6780\n",
      "10/160, train_loss: 0.2925\n",
      "11/160, train_loss: 0.3874\n",
      "12/160, train_loss: 0.4097\n",
      "13/160, train_loss: 0.2897\n",
      "14/160, train_loss: 0.4522\n",
      "15/160, train_loss: 0.3165\n",
      "16/160, train_loss: 0.4220\n",
      "17/160, train_loss: 0.3522\n",
      "18/160, train_loss: 0.3458\n",
      "19/160, train_loss: 0.4532\n",
      "20/160, train_loss: 0.4698\n",
      "21/160, train_loss: 0.4097\n",
      "22/160, train_loss: 0.4357\n",
      "23/160, train_loss: 0.3731\n",
      "24/160, train_loss: 0.5392\n",
      "25/160, train_loss: 0.3829\n",
      "26/160, train_loss: 0.4923\n",
      "27/160, train_loss: 0.4927\n",
      "28/160, train_loss: 0.3959\n",
      "29/160, train_loss: 0.4729\n",
      "30/160, train_loss: 0.4027\n",
      "31/160, train_loss: 0.3560\n",
      "32/160, train_loss: 0.3186\n",
      "33/160, train_loss: 0.4132\n",
      "34/160, train_loss: 0.3295\n",
      "35/160, train_loss: 0.3245\n",
      "36/160, train_loss: 0.4185\n",
      "37/160, train_loss: 0.2952\n",
      "38/160, train_loss: 0.3335\n",
      "39/160, train_loss: 0.3794\n",
      "40/160, train_loss: 0.3914\n",
      "41/160, train_loss: 0.4075\n",
      "42/160, train_loss: 0.3093\n",
      "43/160, train_loss: 0.4052\n",
      "44/160, train_loss: 0.4909\n",
      "45/160, train_loss: 0.3519\n",
      "46/160, train_loss: 0.5308\n",
      "47/160, train_loss: 0.3417\n",
      "48/160, train_loss: 0.3380\n",
      "49/160, train_loss: 0.3146\n",
      "50/160, train_loss: 0.3718\n",
      "51/160, train_loss: 0.3488\n",
      "52/160, train_loss: 0.4141\n",
      "53/160, train_loss: 0.4145\n",
      "54/160, train_loss: 0.3178\n",
      "55/160, train_loss: 0.2844\n",
      "56/160, train_loss: 0.4409\n",
      "57/160, train_loss: 0.4526\n",
      "58/160, train_loss: 0.3373\n",
      "59/160, train_loss: 0.3388\n",
      "60/160, train_loss: 0.3462\n",
      "61/160, train_loss: 0.5087\n",
      "62/160, train_loss: 0.4751\n",
      "63/160, train_loss: 0.3488\n",
      "64/160, train_loss: 0.5679\n",
      "65/160, train_loss: 0.3145\n",
      "66/160, train_loss: 0.4597\n",
      "67/160, train_loss: 0.3395\n",
      "68/160, train_loss: 0.3799\n",
      "69/160, train_loss: 0.4928\n",
      "70/160, train_loss: 0.2875\n",
      "71/160, train_loss: 0.4513\n",
      "72/160, train_loss: 0.3828\n",
      "73/160, train_loss: 0.6351\n",
      "74/160, train_loss: 0.3164\n",
      "75/160, train_loss: 0.2186\n",
      "76/160, train_loss: 0.3713\n",
      "77/160, train_loss: 0.3660\n",
      "78/160, train_loss: 0.2912\n",
      "79/160, train_loss: 0.3482\n",
      "80/160, train_loss: 0.2937\n",
      "81/160, train_loss: 0.2791\n",
      "82/160, train_loss: 0.2715\n",
      "83/160, train_loss: 0.4282\n",
      "84/160, train_loss: 0.3468\n",
      "85/160, train_loss: 0.3831\n",
      "86/160, train_loss: 0.3626\n",
      "87/160, train_loss: 0.4037\n",
      "88/160, train_loss: 0.3291\n",
      "89/160, train_loss: 0.3235\n",
      "90/160, train_loss: 0.3057\n",
      "91/160, train_loss: 0.2182\n",
      "92/160, train_loss: 0.4459\n",
      "93/160, train_loss: 0.3054\n",
      "94/160, train_loss: 0.1826\n",
      "95/160, train_loss: 0.4781\n",
      "96/160, train_loss: 0.3288\n",
      "97/160, train_loss: 0.4236\n",
      "98/160, train_loss: 0.4208\n",
      "99/160, train_loss: 0.4717\n",
      "100/160, train_loss: 0.3942\n",
      "101/160, train_loss: 0.5005\n",
      "102/160, train_loss: 0.3293\n",
      "103/160, train_loss: 0.5263\n",
      "104/160, train_loss: 0.4512\n",
      "105/160, train_loss: 0.2997\n",
      "106/160, train_loss: 0.3579\n",
      "107/160, train_loss: 0.4168\n",
      "108/160, train_loss: 0.3531\n",
      "109/160, train_loss: 0.2412\n",
      "110/160, train_loss: 0.2937\n",
      "111/160, train_loss: 0.3967\n",
      "112/160, train_loss: 0.4533\n",
      "113/160, train_loss: 0.3164\n",
      "114/160, train_loss: 0.3223\n",
      "115/160, train_loss: 0.3204\n",
      "116/160, train_loss: 0.2267\n",
      "117/160, train_loss: 0.3264\n",
      "118/160, train_loss: 0.3012\n",
      "119/160, train_loss: 0.4764\n",
      "120/160, train_loss: 0.2700\n",
      "121/160, train_loss: 0.2961\n",
      "122/160, train_loss: 0.5585\n",
      "123/160, train_loss: 0.3808\n",
      "124/160, train_loss: 0.4774\n",
      "125/160, train_loss: 0.3110\n",
      "126/160, train_loss: 0.3682\n",
      "127/160, train_loss: 0.2285\n",
      "128/160, train_loss: 0.2856\n",
      "129/160, train_loss: 0.4439\n",
      "130/160, train_loss: 0.4430\n",
      "131/160, train_loss: 0.2607\n",
      "132/160, train_loss: 0.4549\n",
      "133/160, train_loss: 0.5484\n",
      "134/160, train_loss: 0.3294\n",
      "135/160, train_loss: 0.4316\n",
      "136/160, train_loss: 0.4627\n",
      "137/160, train_loss: 0.3281\n",
      "138/160, train_loss: 0.3429\n",
      "139/160, train_loss: 0.2353\n",
      "140/160, train_loss: 0.3353\n",
      "141/160, train_loss: 0.3830\n",
      "142/160, train_loss: 0.4082\n",
      "143/160, train_loss: 0.3347\n",
      "144/160, train_loss: 0.3150\n",
      "145/160, train_loss: 0.3044\n",
      "146/160, train_loss: 0.3140\n",
      "147/160, train_loss: 0.2794\n",
      "148/160, train_loss: 0.2718\n",
      "149/160, train_loss: 0.4313\n",
      "150/160, train_loss: 0.3030\n",
      "151/160, train_loss: 0.3779\n",
      "152/160, train_loss: 0.3920\n",
      "153/160, train_loss: 0.3044\n",
      "154/160, train_loss: 0.2803\n",
      "155/160, train_loss: 0.4767\n",
      "156/160, train_loss: 0.3972\n",
      "157/160, train_loss: 0.3013\n",
      "158/160, train_loss: 0.2701\n",
      "159/160, train_loss: 0.4444\n",
      "160/160, train_loss: 0.4471\n",
      "Epoch 3/10 159/160 loss: 0.3746 time 72.83s\n",
      "0/40 dice: 0.7031\n",
      "1/40 dice: 0.6717\n",
      "2/40 dice: 0.4117\n",
      "3/40 dice: 0.6389\n",
      "4/40 dice: 0.5377\n",
      "5/40 dice: 0.5717\n",
      "6/40 dice: 0.6543\n",
      "7/40 dice: 0.5948\n",
      "8/40 dice: 0.4246\n",
      "9/40 dice: 0.6441\n",
      "10/40 dice: 0.5212\n",
      "11/40 dice: 0.6224\n",
      "12/40 dice: 0.2401\n",
      "13/40 dice: 0.4390\n",
      "14/40 dice: 0.4248\n",
      "15/40 dice: 0.5987\n",
      "16/40 dice: 0.6437\n",
      "17/40 dice: 0.6260\n",
      "18/40 dice: 0.6310\n",
      "19/40 dice: 0.6400\n",
      "20/40 dice: 0.6518\n",
      "21/40 dice: 0.5219\n",
      "22/40 dice: 0.5262\n",
      "23/40 dice: 0.5854\n",
      "24/40 dice: 0.5088\n",
      "25/40 dice: 0.6892\n",
      "26/40 dice: 0.6988\n",
      "27/40 dice: 0.6771\n",
      "28/40 dice: 0.6337\n",
      "29/40 dice: 0.6049\n",
      "30/40 dice: 0.5698\n",
      "31/40 dice: 0.5467\n",
      "32/40 dice: 0.4592\n",
      "33/40 dice: 0.6555\n",
      "34/40 dice: 0.6118\n",
      "35/40 dice: 0.5987\n",
      "36/40 dice: 0.3998\n",
      "37/40 dice: 0.5214\n",
      "38/40 dice: 0.7237\n",
      "39/40 dice: 0.6379\n",
      "current epoch: 4 current mean dice: 0.5765 best mean dice: 0.6165 at epoch: 3\n",
      "----------\n",
      "epoch 5/10\n",
      "1/160, train_loss: 0.4342\n",
      "2/160, train_loss: 0.3476\n",
      "3/160, train_loss: 0.3423\n",
      "4/160, train_loss: 0.3729\n",
      "5/160, train_loss: 0.2981\n",
      "6/160, train_loss: 0.2543\n",
      "7/160, train_loss: 0.3347\n",
      "8/160, train_loss: 0.3028\n",
      "9/160, train_loss: 0.2394\n",
      "10/160, train_loss: 0.4064\n",
      "11/160, train_loss: 0.3142\n",
      "12/160, train_loss: 0.3420\n",
      "13/160, train_loss: 0.5624\n",
      "14/160, train_loss: 0.3025\n",
      "15/160, train_loss: 0.2779\n",
      "16/160, train_loss: 0.3139\n",
      "17/160, train_loss: 0.2951\n",
      "18/160, train_loss: 0.3423\n",
      "19/160, train_loss: 0.3177\n",
      "20/160, train_loss: 0.3032\n",
      "21/160, train_loss: 0.2607\n",
      "22/160, train_loss: 0.3964\n",
      "23/160, train_loss: 0.5024\n",
      "24/160, train_loss: 0.3517\n",
      "25/160, train_loss: 0.2417\n",
      "26/160, train_loss: 0.3392\n",
      "27/160, train_loss: 0.5188\n",
      "28/160, train_loss: 0.4814\n",
      "29/160, train_loss: 0.4397\n",
      "30/160, train_loss: 0.3616\n",
      "31/160, train_loss: 0.2755\n",
      "32/160, train_loss: 0.3801\n",
      "33/160, train_loss: 0.3925\n",
      "34/160, train_loss: 0.4653\n",
      "35/160, train_loss: 0.3064\n",
      "36/160, train_loss: 0.3571\n",
      "37/160, train_loss: 0.2110\n",
      "38/160, train_loss: 0.3835\n",
      "39/160, train_loss: 0.3488\n",
      "40/160, train_loss: 0.2338\n",
      "41/160, train_loss: 0.2591\n",
      "42/160, train_loss: 0.3007\n",
      "43/160, train_loss: 0.2882\n",
      "44/160, train_loss: 0.3160\n",
      "45/160, train_loss: 0.3977\n",
      "46/160, train_loss: 0.3302\n",
      "47/160, train_loss: 0.2299\n",
      "48/160, train_loss: 0.4047\n",
      "49/160, train_loss: 0.4170\n",
      "50/160, train_loss: 0.3465\n",
      "51/160, train_loss: 0.3111\n",
      "52/160, train_loss: 0.3658\n",
      "53/160, train_loss: 0.2645\n",
      "54/160, train_loss: 0.3050\n",
      "55/160, train_loss: 0.3774\n",
      "56/160, train_loss: 0.4045\n",
      "57/160, train_loss: 0.3408\n",
      "58/160, train_loss: 0.2438\n",
      "59/160, train_loss: 0.2953\n",
      "60/160, train_loss: 0.3179\n",
      "61/160, train_loss: 0.3758\n",
      "62/160, train_loss: 0.3637\n",
      "63/160, train_loss: 0.4008\n",
      "64/160, train_loss: 0.3113\n",
      "65/160, train_loss: 0.2894\n",
      "66/160, train_loss: 0.2934\n",
      "67/160, train_loss: 0.4400\n",
      "68/160, train_loss: 0.3765\n",
      "69/160, train_loss: 0.4144\n",
      "70/160, train_loss: 0.4932\n",
      "71/160, train_loss: 0.3162\n",
      "72/160, train_loss: 0.2782\n",
      "73/160, train_loss: 0.4111\n",
      "74/160, train_loss: 0.3617\n",
      "75/160, train_loss: 0.7374\n",
      "76/160, train_loss: 0.5175\n",
      "77/160, train_loss: 0.4246\n",
      "78/160, train_loss: 0.1900\n",
      "79/160, train_loss: 0.2505\n",
      "80/160, train_loss: 0.3259\n",
      "81/160, train_loss: 0.3720\n",
      "82/160, train_loss: 0.4785\n",
      "83/160, train_loss: 0.2890\n",
      "84/160, train_loss: 0.4654\n",
      "85/160, train_loss: 0.5066\n",
      "86/160, train_loss: 0.3249\n",
      "87/160, train_loss: 0.2655\n",
      "88/160, train_loss: 0.3608\n",
      "89/160, train_loss: 0.4401\n",
      "90/160, train_loss: 0.3238\n",
      "91/160, train_loss: 0.2861\n",
      "92/160, train_loss: 0.3894\n",
      "93/160, train_loss: 0.2815\n",
      "94/160, train_loss: 0.2636\n",
      "95/160, train_loss: 0.2744\n",
      "96/160, train_loss: 0.4461\n",
      "97/160, train_loss: 0.2995\n",
      "98/160, train_loss: 0.3275\n",
      "99/160, train_loss: 0.3954\n",
      "100/160, train_loss: 0.3180\n",
      "101/160, train_loss: 0.3087\n",
      "102/160, train_loss: 0.4031\n",
      "103/160, train_loss: 0.2528\n",
      "104/160, train_loss: 0.3143\n",
      "105/160, train_loss: 0.2366\n",
      "106/160, train_loss: 0.3098\n",
      "107/160, train_loss: 0.3934\n",
      "108/160, train_loss: 0.3714\n",
      "109/160, train_loss: 0.2979\n",
      "110/160, train_loss: 0.3346\n",
      "111/160, train_loss: 0.2974\n",
      "112/160, train_loss: 0.3826\n",
      "113/160, train_loss: 0.2438\n",
      "114/160, train_loss: 0.2294\n",
      "115/160, train_loss: 0.3962\n",
      "116/160, train_loss: 0.2959\n",
      "117/160, train_loss: 0.5352\n",
      "118/160, train_loss: 0.2659\n",
      "119/160, train_loss: 0.2921\n",
      "120/160, train_loss: 0.3611\n",
      "121/160, train_loss: 0.4092\n",
      "122/160, train_loss: 0.3680\n",
      "123/160, train_loss: 0.2247\n",
      "124/160, train_loss: 0.3277\n",
      "125/160, train_loss: 0.3040\n",
      "126/160, train_loss: 0.3200\n",
      "127/160, train_loss: 0.2364\n",
      "128/160, train_loss: 0.3057\n",
      "129/160, train_loss: 0.3556\n",
      "130/160, train_loss: 0.2816\n",
      "131/160, train_loss: 0.4041\n",
      "132/160, train_loss: 0.4669\n",
      "133/160, train_loss: 0.2615\n",
      "134/160, train_loss: 0.3973\n",
      "135/160, train_loss: 0.3758\n",
      "136/160, train_loss: 0.4415\n",
      "137/160, train_loss: 0.2531\n",
      "138/160, train_loss: 0.3497\n",
      "139/160, train_loss: 0.4433\n",
      "140/160, train_loss: 0.2591\n",
      "141/160, train_loss: 0.3729\n",
      "142/160, train_loss: 0.2825\n",
      "143/160, train_loss: 0.3451\n",
      "144/160, train_loss: 0.3217\n",
      "145/160, train_loss: 0.4048\n",
      "146/160, train_loss: 0.3644\n",
      "147/160, train_loss: 0.5534\n",
      "148/160, train_loss: 0.1945\n",
      "149/160, train_loss: 0.3269\n",
      "150/160, train_loss: 0.2813\n",
      "151/160, train_loss: 0.3048\n",
      "152/160, train_loss: 0.4318\n",
      "153/160, train_loss: 0.5580\n",
      "154/160, train_loss: 0.2727\n",
      "155/160, train_loss: 0.4123\n",
      "156/160, train_loss: 0.2410\n",
      "157/160, train_loss: 0.2736\n",
      "158/160, train_loss: 0.3126\n",
      "159/160, train_loss: 0.4340\n",
      "160/160, train_loss: 0.2802\n",
      "Epoch 4/10 159/160 loss: 0.3464 time 72.22s\n",
      "0/40 dice: 0.7275\n",
      "1/40 dice: 0.6729\n",
      "2/40 dice: 0.4655\n",
      "3/40 dice: 0.6098\n",
      "4/40 dice: 0.5993\n",
      "5/40 dice: 0.6513\n",
      "6/40 dice: 0.7062\n",
      "7/40 dice: 0.6524\n",
      "8/40 dice: 0.5721\n",
      "9/40 dice: 0.6530\n",
      "10/40 dice: 0.6146\n",
      "11/40 dice: 0.7261\n",
      "12/40 dice: 0.4083\n",
      "13/40 dice: 0.4684\n",
      "14/40 dice: 0.5335\n",
      "15/40 dice: 0.6441\n",
      "16/40 dice: 0.6632\n",
      "17/40 dice: 0.6306\n",
      "18/40 dice: 0.6302\n",
      "19/40 dice: 0.6106\n",
      "20/40 dice: 0.6341\n",
      "21/40 dice: 0.5028\n",
      "22/40 dice: 0.4919\n",
      "23/40 dice: 0.6135\n",
      "24/40 dice: 0.6725\n",
      "25/40 dice: 0.6806\n",
      "26/40 dice: 0.7182\n",
      "27/40 dice: 0.7363\n",
      "28/40 dice: 0.6895\n",
      "29/40 dice: 0.5967\n",
      "30/40 dice: 0.5591\n",
      "31/40 dice: 0.5841\n",
      "32/40 dice: 0.4871\n",
      "33/40 dice: 0.6956\n",
      "34/40 dice: 0.6353\n",
      "35/40 dice: 0.6791\n",
      "36/40 dice: 0.5692\n",
      "37/40 dice: 0.5617\n",
      "38/40 dice: 0.7220\n",
      "39/40 dice: 0.6601\n",
      "saved new best metric model\n",
      "current epoch: 5 current mean dice: 0.6182 best mean dice: 0.6182 at epoch: 5\n",
      "----------\n",
      "epoch 6/10\n",
      "1/160, train_loss: 0.4086\n",
      "2/160, train_loss: 0.4905\n",
      "3/160, train_loss: 0.3260\n",
      "4/160, train_loss: 0.3142\n",
      "5/160, train_loss: 0.3193\n",
      "6/160, train_loss: 0.2971\n",
      "7/160, train_loss: 0.5228\n",
      "8/160, train_loss: 0.2155\n",
      "9/160, train_loss: 0.2561\n",
      "10/160, train_loss: 0.3379\n",
      "11/160, train_loss: 0.2943\n",
      "12/160, train_loss: 0.3729\n",
      "13/160, train_loss: 0.3249\n",
      "14/160, train_loss: 0.2475\n",
      "15/160, train_loss: 0.4149\n",
      "16/160, train_loss: 0.3852\n",
      "17/160, train_loss: 0.3228\n",
      "18/160, train_loss: 0.4561\n",
      "19/160, train_loss: 0.3132\n",
      "20/160, train_loss: 0.4387\n",
      "21/160, train_loss: 0.5220\n",
      "22/160, train_loss: 0.3686\n",
      "23/160, train_loss: 0.3380\n",
      "24/160, train_loss: 0.3517\n",
      "25/160, train_loss: 0.3348\n",
      "26/160, train_loss: 0.4451\n",
      "27/160, train_loss: 0.3184\n",
      "28/160, train_loss: 0.2880\n",
      "29/160, train_loss: 0.3951\n",
      "30/160, train_loss: 0.4403\n",
      "31/160, train_loss: 0.5122\n",
      "32/160, train_loss: 0.2128\n",
      "33/160, train_loss: 0.5832\n",
      "34/160, train_loss: 0.3295\n",
      "35/160, train_loss: 0.4373\n",
      "36/160, train_loss: 0.2646\n",
      "37/160, train_loss: 0.4043\n",
      "38/160, train_loss: 0.3863\n",
      "39/160, train_loss: 0.3320\n",
      "40/160, train_loss: 0.3415\n",
      "41/160, train_loss: 0.3426\n",
      "42/160, train_loss: 0.2714\n",
      "43/160, train_loss: 0.2325\n",
      "44/160, train_loss: 0.2662\n",
      "45/160, train_loss: 0.3100\n",
      "46/160, train_loss: 0.3114\n",
      "47/160, train_loss: 0.3803\n",
      "48/160, train_loss: 0.3758\n",
      "49/160, train_loss: 0.4807\n",
      "50/160, train_loss: 0.2234\n",
      "51/160, train_loss: 0.3198\n",
      "52/160, train_loss: 0.2755\n",
      "53/160, train_loss: 0.3232\n",
      "54/160, train_loss: 0.2909\n",
      "55/160, train_loss: 0.4081\n",
      "56/160, train_loss: 0.2681\n",
      "57/160, train_loss: 0.2777\n",
      "58/160, train_loss: 0.3946\n",
      "59/160, train_loss: 0.2251\n",
      "60/160, train_loss: 0.3186\n",
      "61/160, train_loss: 0.4068\n",
      "62/160, train_loss: 0.4831\n",
      "63/160, train_loss: 0.3518\n",
      "64/160, train_loss: 0.2811\n",
      "65/160, train_loss: 0.3766\n",
      "66/160, train_loss: 0.3159\n",
      "67/160, train_loss: 0.3263\n",
      "68/160, train_loss: 0.3018\n",
      "69/160, train_loss: 0.2650\n",
      "70/160, train_loss: 0.2410\n",
      "71/160, train_loss: 0.3870\n",
      "72/160, train_loss: 0.6681\n",
      "73/160, train_loss: 0.4463\n",
      "74/160, train_loss: 0.2718\n",
      "75/160, train_loss: 0.3250\n",
      "76/160, train_loss: 0.2842\n",
      "77/160, train_loss: 0.3831\n",
      "78/160, train_loss: 0.3649\n",
      "79/160, train_loss: 0.2915\n",
      "80/160, train_loss: 0.3480\n",
      "81/160, train_loss: 0.2888\n",
      "82/160, train_loss: 0.3087\n",
      "83/160, train_loss: 0.1905\n",
      "84/160, train_loss: 0.3221\n",
      "85/160, train_loss: 0.3053\n",
      "86/160, train_loss: 0.2510\n",
      "87/160, train_loss: 0.3301\n",
      "88/160, train_loss: 0.3304\n",
      "89/160, train_loss: 0.3168\n",
      "90/160, train_loss: 0.2324\n",
      "91/160, train_loss: 0.3291\n",
      "92/160, train_loss: 0.3474\n",
      "93/160, train_loss: 0.4388\n",
      "94/160, train_loss: 0.3477\n",
      "95/160, train_loss: 0.2696\n",
      "96/160, train_loss: 0.4768\n",
      "97/160, train_loss: 0.2381\n",
      "98/160, train_loss: 0.3119\n",
      "99/160, train_loss: 0.7227\n",
      "100/160, train_loss: 0.3498\n",
      "101/160, train_loss: 0.3546\n",
      "102/160, train_loss: 0.4204\n",
      "103/160, train_loss: 0.2429\n",
      "104/160, train_loss: 0.3227\n",
      "105/160, train_loss: 0.3820\n",
      "106/160, train_loss: 0.4127\n",
      "107/160, train_loss: 0.3054\n",
      "108/160, train_loss: 0.5629\n",
      "109/160, train_loss: 0.3260\n",
      "110/160, train_loss: 0.3671\n",
      "111/160, train_loss: 0.3654\n",
      "112/160, train_loss: 0.3165\n",
      "113/160, train_loss: 0.3591\n",
      "114/160, train_loss: 0.3435\n",
      "115/160, train_loss: 0.2431\n",
      "116/160, train_loss: 0.3101\n",
      "117/160, train_loss: 0.3341\n",
      "118/160, train_loss: 0.2717\n",
      "119/160, train_loss: 0.3608\n",
      "120/160, train_loss: 0.2401\n",
      "121/160, train_loss: 0.4284\n",
      "122/160, train_loss: 0.2403\n",
      "123/160, train_loss: 0.3300\n",
      "124/160, train_loss: 0.3457\n",
      "125/160, train_loss: 0.3464\n",
      "126/160, train_loss: 0.3197\n",
      "127/160, train_loss: 0.2545\n",
      "128/160, train_loss: 0.3142\n",
      "129/160, train_loss: 0.4612\n",
      "130/160, train_loss: 0.2594\n",
      "131/160, train_loss: 0.2395\n",
      "132/160, train_loss: 0.3657\n",
      "133/160, train_loss: 0.2748\n",
      "134/160, train_loss: 0.4747\n",
      "135/160, train_loss: 0.4448\n",
      "136/160, train_loss: 0.2009\n",
      "137/160, train_loss: 0.3244\n",
      "138/160, train_loss: 0.2690\n",
      "139/160, train_loss: 0.3996\n",
      "140/160, train_loss: 0.3682\n",
      "141/160, train_loss: 0.3594\n",
      "142/160, train_loss: 0.4388\n",
      "143/160, train_loss: 0.4400\n",
      "144/160, train_loss: 0.3743\n",
      "145/160, train_loss: 0.2709\n",
      "146/160, train_loss: 0.4355\n",
      "147/160, train_loss: 0.3190\n",
      "148/160, train_loss: 0.3463\n",
      "149/160, train_loss: 0.4383\n",
      "150/160, train_loss: 0.5577\n",
      "151/160, train_loss: 0.2419\n",
      "152/160, train_loss: 0.2994\n",
      "153/160, train_loss: 0.2952\n",
      "154/160, train_loss: 0.3245\n",
      "155/160, train_loss: 0.3166\n",
      "156/160, train_loss: 0.3924\n",
      "157/160, train_loss: 0.3391\n",
      "158/160, train_loss: 0.3044\n",
      "159/160, train_loss: 0.2234\n",
      "160/160, train_loss: 0.3608\n",
      "Epoch 5/10 159/160 loss: 0.3460 time 73.11s\n",
      "0/40 dice: 0.7518\n",
      "1/40 dice: 0.6484\n",
      "2/40 dice: 0.6109\n",
      "3/40 dice: 0.6709\n",
      "4/40 dice: 0.6647\n",
      "5/40 dice: 0.7368\n",
      "6/40 dice: 0.7171\n",
      "7/40 dice: 0.6968\n",
      "8/40 dice: 0.6703\n",
      "9/40 dice: 0.7397\n",
      "10/40 dice: 0.6223\n",
      "11/40 dice: 0.7573\n",
      "12/40 dice: 0.4973\n",
      "13/40 dice: 0.6078\n",
      "14/40 dice: 0.6007\n",
      "15/40 dice: 0.6741\n",
      "16/40 dice: 0.6807\n",
      "17/40 dice: 0.6616\n",
      "18/40 dice: 0.6706\n",
      "19/40 dice: 0.6762\n",
      "20/40 dice: 0.7392\n",
      "21/40 dice: 0.6272\n",
      "22/40 dice: 0.6184\n",
      "23/40 dice: 0.6938\n",
      "24/40 dice: 0.7149\n",
      "25/40 dice: 0.6578\n",
      "26/40 dice: 0.7396\n",
      "27/40 dice: 0.7137\n",
      "28/40 dice: 0.7196\n",
      "29/40 dice: 0.6849\n",
      "30/40 dice: 0.6747\n",
      "31/40 dice: 0.6462\n",
      "32/40 dice: 0.5879\n",
      "33/40 dice: 0.6613\n",
      "34/40 dice: 0.6900\n",
      "35/40 dice: 0.6595\n",
      "36/40 dice: 0.5883\n",
      "37/40 dice: 0.6426\n",
      "38/40 dice: 0.7473\n",
      "39/40 dice: 0.6707\n",
      "saved new best metric model\n",
      "current epoch: 6 current mean dice: 0.6708 best mean dice: 0.6708 at epoch: 6\n",
      "----------\n",
      "epoch 7/10\n",
      "1/160, train_loss: 0.4114\n",
      "2/160, train_loss: 0.2243\n",
      "3/160, train_loss: 0.2245\n",
      "4/160, train_loss: 0.2335\n",
      "5/160, train_loss: 0.3297\n",
      "6/160, train_loss: 0.3526\n",
      "7/160, train_loss: 0.3095\n",
      "8/160, train_loss: 0.3792\n",
      "9/160, train_loss: 0.3366\n",
      "10/160, train_loss: 0.4563\n",
      "11/160, train_loss: 0.2159\n",
      "12/160, train_loss: 0.4218\n",
      "13/160, train_loss: 0.3208\n",
      "14/160, train_loss: 0.3422\n",
      "15/160, train_loss: 0.3534\n",
      "16/160, train_loss: 0.5039\n",
      "17/160, train_loss: 0.4030\n",
      "18/160, train_loss: 0.2873\n",
      "19/160, train_loss: 0.3902\n",
      "20/160, train_loss: 0.3553\n",
      "21/160, train_loss: 0.4477\n",
      "22/160, train_loss: 0.5290\n",
      "23/160, train_loss: 0.4827\n",
      "24/160, train_loss: 0.3484\n",
      "25/160, train_loss: 0.2741\n",
      "26/160, train_loss: 0.4100\n",
      "27/160, train_loss: 0.2709\n",
      "28/160, train_loss: 0.2938\n",
      "29/160, train_loss: 0.3551\n",
      "30/160, train_loss: 0.4735\n",
      "31/160, train_loss: 0.3479\n",
      "32/160, train_loss: 0.4034\n",
      "33/160, train_loss: 0.3442\n",
      "34/160, train_loss: 0.2539\n",
      "35/160, train_loss: 0.2636\n",
      "36/160, train_loss: 0.3193\n",
      "37/160, train_loss: 0.2432\n",
      "38/160, train_loss: 0.4098\n",
      "39/160, train_loss: 0.2277\n",
      "40/160, train_loss: 0.2820\n",
      "41/160, train_loss: 0.2185\n",
      "42/160, train_loss: 0.3334\n",
      "43/160, train_loss: 0.2544\n",
      "44/160, train_loss: 0.2825\n",
      "45/160, train_loss: 0.3889\n",
      "46/160, train_loss: 0.3820\n",
      "47/160, train_loss: 0.2361\n",
      "48/160, train_loss: 0.3309\n",
      "49/160, train_loss: 0.2969\n",
      "50/160, train_loss: 0.3600\n",
      "51/160, train_loss: 0.3515\n",
      "52/160, train_loss: 0.4451\n",
      "53/160, train_loss: 0.2860\n",
      "54/160, train_loss: 0.3955\n",
      "55/160, train_loss: 0.3788\n",
      "56/160, train_loss: 0.3126\n",
      "57/160, train_loss: 0.2212\n",
      "58/160, train_loss: 0.2561\n",
      "59/160, train_loss: 0.3527\n",
      "60/160, train_loss: 0.3527\n",
      "61/160, train_loss: 0.3770\n",
      "62/160, train_loss: 0.3471\n",
      "63/160, train_loss: 0.3815\n",
      "64/160, train_loss: 0.2158\n",
      "65/160, train_loss: 0.2412\n",
      "66/160, train_loss: 0.3231\n",
      "67/160, train_loss: 0.4106\n",
      "68/160, train_loss: 0.2610\n",
      "69/160, train_loss: 0.2751\n",
      "70/160, train_loss: 0.2532\n",
      "71/160, train_loss: 0.4459\n",
      "72/160, train_loss: 0.3002\n",
      "73/160, train_loss: 0.2619\n",
      "74/160, train_loss: 0.3737\n",
      "75/160, train_loss: 0.3339\n",
      "76/160, train_loss: 0.3559\n",
      "77/160, train_loss: 0.3070\n",
      "78/160, train_loss: 0.2380\n",
      "79/160, train_loss: 0.2317\n",
      "80/160, train_loss: 0.3049\n",
      "81/160, train_loss: 0.4198\n",
      "82/160, train_loss: 0.6604\n",
      "83/160, train_loss: 0.2221\n",
      "84/160, train_loss: 0.3194\n",
      "85/160, train_loss: 0.2965\n",
      "86/160, train_loss: 0.3008\n",
      "87/160, train_loss: 0.3232\n",
      "88/160, train_loss: 0.2616\n",
      "89/160, train_loss: 0.3629\n",
      "90/160, train_loss: 0.3513\n",
      "91/160, train_loss: 0.3717\n",
      "92/160, train_loss: 0.2796\n",
      "93/160, train_loss: 0.2236\n",
      "94/160, train_loss: 0.3052\n",
      "95/160, train_loss: 0.2244\n",
      "96/160, train_loss: 0.2388\n",
      "97/160, train_loss: 0.2310\n",
      "98/160, train_loss: 0.3180\n",
      "99/160, train_loss: 0.2692\n",
      "100/160, train_loss: 0.3730\n",
      "101/160, train_loss: 0.3721\n",
      "102/160, train_loss: 0.2251\n",
      "103/160, train_loss: 0.3240\n",
      "104/160, train_loss: 0.2417\n",
      "105/160, train_loss: 0.3438\n",
      "106/160, train_loss: 0.2839\n",
      "107/160, train_loss: 0.2480\n",
      "108/160, train_loss: 0.2484\n",
      "109/160, train_loss: 0.4014\n",
      "110/160, train_loss: 0.2470\n",
      "111/160, train_loss: 0.2824\n",
      "112/160, train_loss: 0.2222\n",
      "113/160, train_loss: 0.3569\n",
      "114/160, train_loss: 0.4723\n",
      "115/160, train_loss: 0.4955\n",
      "116/160, train_loss: 0.4023\n",
      "117/160, train_loss: 0.3245\n",
      "118/160, train_loss: 0.3370\n",
      "119/160, train_loss: 0.4334\n",
      "120/160, train_loss: 0.4245\n",
      "121/160, train_loss: 0.6045\n",
      "122/160, train_loss: 0.4190\n",
      "123/160, train_loss: 0.4382\n",
      "124/160, train_loss: 0.3094\n",
      "125/160, train_loss: 0.3991\n",
      "126/160, train_loss: 0.4114\n",
      "127/160, train_loss: 0.6031\n",
      "128/160, train_loss: 0.3475\n",
      "129/160, train_loss: 0.4188\n",
      "130/160, train_loss: 0.3665\n",
      "131/160, train_loss: 0.3977\n",
      "132/160, train_loss: 0.2513\n",
      "133/160, train_loss: 0.3777\n",
      "134/160, train_loss: 0.3256\n",
      "135/160, train_loss: 0.2402\n",
      "136/160, train_loss: 0.3363\n",
      "137/160, train_loss: 0.3074\n",
      "138/160, train_loss: 0.2407\n",
      "139/160, train_loss: 0.3419\n",
      "140/160, train_loss: 0.2649\n",
      "141/160, train_loss: 0.2106\n",
      "142/160, train_loss: 0.2551\n",
      "143/160, train_loss: 0.3644\n",
      "144/160, train_loss: 0.2994\n",
      "145/160, train_loss: 0.4249\n",
      "146/160, train_loss: 0.3033\n",
      "147/160, train_loss: 0.4488\n",
      "148/160, train_loss: 0.4064\n",
      "149/160, train_loss: 0.5116\n",
      "150/160, train_loss: 0.3545\n",
      "151/160, train_loss: 0.3216\n",
      "152/160, train_loss: 0.2805\n",
      "153/160, train_loss: 0.3457\n",
      "154/160, train_loss: 0.3135\n",
      "155/160, train_loss: 0.4495\n",
      "156/160, train_loss: 0.4571\n",
      "157/160, train_loss: 0.3101\n",
      "158/160, train_loss: 0.3060\n",
      "159/160, train_loss: 0.2504\n",
      "160/160, train_loss: 0.2890\n",
      "Epoch 6/10 159/160 loss: 0.3366 time 72.83s\n",
      "0/40 dice: 0.7573\n",
      "1/40 dice: 0.6615\n",
      "2/40 dice: 0.6489\n",
      "3/40 dice: 0.6538\n",
      "4/40 dice: 0.6659\n",
      "5/40 dice: 0.7205\n",
      "6/40 dice: 0.7455\n",
      "7/40 dice: 0.6783\n",
      "8/40 dice: 0.6990\n",
      "9/40 dice: 0.7360\n",
      "10/40 dice: 0.6014\n",
      "11/40 dice: 0.7396\n",
      "12/40 dice: 0.5196\n",
      "13/40 dice: 0.6248\n",
      "14/40 dice: 0.5951\n",
      "15/40 dice: 0.6517\n",
      "16/40 dice: 0.6799\n",
      "17/40 dice: 0.6552\n",
      "18/40 dice: 0.6762\n",
      "19/40 dice: 0.6441\n",
      "20/40 dice: 0.7104\n",
      "21/40 dice: 0.6248\n",
      "22/40 dice: 0.6219\n",
      "23/40 dice: 0.6809\n",
      "24/40 dice: 0.7067\n",
      "25/40 dice: 0.7155\n",
      "26/40 dice: 0.7365\n",
      "27/40 dice: 0.7248\n",
      "28/40 dice: 0.7098\n",
      "29/40 dice: 0.6646\n",
      "30/40 dice: 0.6937\n",
      "31/40 dice: 0.6485\n",
      "32/40 dice: 0.5673\n",
      "33/40 dice: 0.6821\n",
      "34/40 dice: 0.6587\n",
      "35/40 dice: 0.6413\n",
      "36/40 dice: 0.5887\n",
      "37/40 dice: 0.6196\n",
      "38/40 dice: 0.7502\n",
      "39/40 dice: 0.6452\n",
      "current epoch: 7 current mean dice: 0.6686 best mean dice: 0.6708 at epoch: 6\n",
      "----------\n",
      "epoch 8/10\n",
      "1/160, train_loss: 0.3986\n",
      "2/160, train_loss: 0.4536\n",
      "3/160, train_loss: 0.2323\n",
      "4/160, train_loss: 0.3175\n",
      "5/160, train_loss: 0.3117\n",
      "6/160, train_loss: 0.7374\n",
      "7/160, train_loss: 0.3445\n",
      "8/160, train_loss: 0.2474\n",
      "9/160, train_loss: 0.2065\n",
      "10/160, train_loss: 0.4191\n",
      "11/160, train_loss: 0.3420\n",
      "12/160, train_loss: 0.3641\n",
      "13/160, train_loss: 0.3661\n",
      "14/160, train_loss: 0.5106\n",
      "15/160, train_loss: 0.2734\n",
      "16/160, train_loss: 0.2389\n",
      "17/160, train_loss: 0.2623\n",
      "18/160, train_loss: 0.4898\n",
      "19/160, train_loss: 0.2921\n",
      "20/160, train_loss: 0.2330\n",
      "21/160, train_loss: 0.4253\n",
      "22/160, train_loss: 0.2508\n",
      "23/160, train_loss: 0.2703\n",
      "24/160, train_loss: 0.3009\n",
      "25/160, train_loss: 0.4505\n",
      "26/160, train_loss: 0.2319\n",
      "27/160, train_loss: 0.3039\n",
      "28/160, train_loss: 0.3690\n",
      "29/160, train_loss: 0.2400\n",
      "30/160, train_loss: 0.2989\n",
      "31/160, train_loss: 0.3333\n",
      "32/160, train_loss: 0.3909\n",
      "33/160, train_loss: 0.5113\n",
      "34/160, train_loss: 0.3281\n",
      "35/160, train_loss: 0.3228\n",
      "36/160, train_loss: 0.2540\n",
      "37/160, train_loss: 0.2992\n",
      "38/160, train_loss: 0.6263\n",
      "39/160, train_loss: 0.3082\n",
      "40/160, train_loss: 0.2658\n",
      "41/160, train_loss: 0.3424\n",
      "42/160, train_loss: 0.3168\n",
      "43/160, train_loss: 0.4347\n",
      "44/160, train_loss: 0.4309\n",
      "45/160, train_loss: 0.2996\n",
      "46/160, train_loss: 0.3590\n",
      "47/160, train_loss: 0.3215\n",
      "48/160, train_loss: 0.5344\n",
      "49/160, train_loss: 0.3531\n",
      "50/160, train_loss: 0.3040\n",
      "51/160, train_loss: 0.4370\n",
      "52/160, train_loss: 0.3114\n",
      "53/160, train_loss: 0.3481\n",
      "54/160, train_loss: 0.3751\n",
      "55/160, train_loss: 0.2772\n",
      "56/160, train_loss: 0.3493\n",
      "57/160, train_loss: 0.3381\n",
      "58/160, train_loss: 0.2687\n",
      "59/160, train_loss: 0.3769\n",
      "60/160, train_loss: 0.3739\n",
      "61/160, train_loss: 0.4441\n",
      "62/160, train_loss: 0.2952\n",
      "63/160, train_loss: 0.3250\n",
      "64/160, train_loss: 0.2640\n",
      "65/160, train_loss: 0.3890\n",
      "66/160, train_loss: 0.4864\n",
      "67/160, train_loss: 0.2829\n",
      "68/160, train_loss: 0.4468\n",
      "69/160, train_loss: 0.1593\n",
      "70/160, train_loss: 0.3219\n",
      "71/160, train_loss: 0.2880\n",
      "72/160, train_loss: 0.2705\n",
      "73/160, train_loss: 0.3462\n",
      "74/160, train_loss: 0.3714\n",
      "75/160, train_loss: 0.4947\n",
      "76/160, train_loss: 0.3414\n",
      "77/160, train_loss: 0.2833\n",
      "78/160, train_loss: 0.2646\n",
      "79/160, train_loss: 0.2198\n",
      "80/160, train_loss: 0.3193\n",
      "81/160, train_loss: 0.3273\n",
      "82/160, train_loss: 0.4095\n",
      "83/160, train_loss: 0.4238\n",
      "84/160, train_loss: 0.2977\n",
      "85/160, train_loss: 0.2162\n",
      "86/160, train_loss: 0.2702\n",
      "87/160, train_loss: 0.2588\n",
      "88/160, train_loss: 0.3644\n",
      "89/160, train_loss: 0.2765\n",
      "90/160, train_loss: 0.2252\n",
      "91/160, train_loss: 0.3214\n",
      "92/160, train_loss: 0.2611\n",
      "93/160, train_loss: 0.2909\n",
      "94/160, train_loss: 0.2648\n",
      "95/160, train_loss: 0.2836\n",
      "96/160, train_loss: 0.2984\n",
      "97/160, train_loss: 0.3173\n",
      "98/160, train_loss: 0.2538\n",
      "99/160, train_loss: 0.3569\n",
      "100/160, train_loss: 0.3487\n",
      "101/160, train_loss: 0.2209\n",
      "102/160, train_loss: 0.4073\n",
      "103/160, train_loss: 0.3130\n",
      "104/160, train_loss: 0.3283\n",
      "105/160, train_loss: 0.2923\n",
      "106/160, train_loss: 0.2163\n",
      "107/160, train_loss: 0.3696\n",
      "108/160, train_loss: 0.1991\n",
      "109/160, train_loss: 0.3132\n",
      "110/160, train_loss: 0.2929\n",
      "111/160, train_loss: 0.2598\n",
      "112/160, train_loss: 0.4640\n",
      "113/160, train_loss: 0.3153\n",
      "114/160, train_loss: 0.3142\n",
      "115/160, train_loss: 0.3800\n",
      "116/160, train_loss: 0.2444\n",
      "117/160, train_loss: 0.3290\n",
      "118/160, train_loss: 0.2514\n",
      "119/160, train_loss: 0.3872\n",
      "120/160, train_loss: 0.2914\n",
      "121/160, train_loss: 0.3292\n",
      "122/160, train_loss: 0.4078\n",
      "123/160, train_loss: 0.3331\n",
      "124/160, train_loss: 0.3041\n",
      "125/160, train_loss: 0.2377\n",
      "126/160, train_loss: 0.3209\n",
      "127/160, train_loss: 0.2458\n",
      "128/160, train_loss: 0.2761\n",
      "129/160, train_loss: 0.2884\n",
      "130/160, train_loss: 0.2417\n",
      "131/160, train_loss: 0.3716\n",
      "132/160, train_loss: 0.2588\n",
      "133/160, train_loss: 0.4834\n",
      "134/160, train_loss: 0.4138\n",
      "135/160, train_loss: 0.2358\n",
      "136/160, train_loss: 0.2871\n",
      "137/160, train_loss: 0.3396\n",
      "138/160, train_loss: 0.3192\n",
      "139/160, train_loss: 0.3626\n",
      "140/160, train_loss: 0.3116\n",
      "141/160, train_loss: 0.3897\n",
      "142/160, train_loss: 0.2222\n",
      "143/160, train_loss: 0.3328\n",
      "144/160, train_loss: 0.2338\n",
      "145/160, train_loss: 0.2621\n",
      "146/160, train_loss: 0.2808\n",
      "147/160, train_loss: 0.2421\n",
      "148/160, train_loss: 0.1742\n",
      "149/160, train_loss: 0.1904\n",
      "150/160, train_loss: 0.3099\n",
      "151/160, train_loss: 0.2437\n",
      "152/160, train_loss: 0.2569\n",
      "153/160, train_loss: 0.2553\n",
      "154/160, train_loss: 0.2474\n",
      "155/160, train_loss: 0.3132\n",
      "156/160, train_loss: 0.2920\n",
      "157/160, train_loss: 0.2783\n",
      "158/160, train_loss: 0.2289\n",
      "159/160, train_loss: 0.2659\n",
      "160/160, train_loss: 0.2751\n",
      "Epoch 7/10 159/160 loss: 0.3219 time 72.73s\n",
      "0/40 dice: 0.7805\n",
      "1/40 dice: 0.7402\n",
      "2/40 dice: 0.6121\n",
      "3/40 dice: 0.7318\n",
      "4/40 dice: 0.6937\n",
      "5/40 dice: 0.7703\n",
      "6/40 dice: 0.7998\n",
      "7/40 dice: 0.7290\n",
      "8/40 dice: 0.7166\n",
      "9/40 dice: 0.7636\n",
      "10/40 dice: 0.6672\n",
      "11/40 dice: 0.8107\n",
      "12/40 dice: 0.5974\n",
      "13/40 dice: 0.6328\n",
      "14/40 dice: 0.6197\n",
      "15/40 dice: 0.7023\n",
      "16/40 dice: 0.7400\n",
      "17/40 dice: 0.6840\n",
      "18/40 dice: 0.7035\n",
      "19/40 dice: 0.6584\n",
      "20/40 dice: 0.7442\n",
      "21/40 dice: 0.6310\n",
      "22/40 dice: 0.6712\n",
      "23/40 dice: 0.6928\n",
      "24/40 dice: 0.7713\n",
      "25/40 dice: 0.7383\n",
      "26/40 dice: 0.7703\n",
      "27/40 dice: 0.7710\n",
      "28/40 dice: 0.7293\n",
      "29/40 dice: 0.6804\n",
      "30/40 dice: 0.6969\n",
      "31/40 dice: 0.6586\n",
      "32/40 dice: 0.6501\n",
      "33/40 dice: 0.7435\n",
      "34/40 dice: 0.7235\n",
      "35/40 dice: 0.7220\n",
      "36/40 dice: 0.6463\n",
      "37/40 dice: 0.6847\n",
      "38/40 dice: 0.7998\n",
      "39/40 dice: 0.6933\n",
      "saved new best metric model\n",
      "current epoch: 8 current mean dice: 0.7093 best mean dice: 0.7093 at epoch: 8\n",
      "----------\n",
      "epoch 9/10\n",
      "1/160, train_loss: 0.2569\n",
      "2/160, train_loss: 0.3213\n",
      "3/160, train_loss: 0.2530\n",
      "4/160, train_loss: 0.3543\n",
      "5/160, train_loss: 0.1883\n",
      "6/160, train_loss: 0.4317\n",
      "7/160, train_loss: 0.2628\n",
      "8/160, train_loss: 0.4757\n",
      "9/160, train_loss: 0.2738\n",
      "10/160, train_loss: 0.2715\n",
      "11/160, train_loss: 0.2884\n",
      "12/160, train_loss: 0.2187\n",
      "13/160, train_loss: 0.3293\n",
      "14/160, train_loss: 0.2247\n",
      "15/160, train_loss: 0.6636\n",
      "16/160, train_loss: 0.4053\n",
      "17/160, train_loss: 0.2757\n",
      "18/160, train_loss: 0.2343\n",
      "19/160, train_loss: 0.2536\n",
      "20/160, train_loss: 0.2598\n",
      "21/160, train_loss: 0.3064\n",
      "22/160, train_loss: 0.2607\n",
      "23/160, train_loss: 0.2148\n",
      "24/160, train_loss: 0.2248\n",
      "25/160, train_loss: 0.4128\n",
      "26/160, train_loss: 0.3036\n",
      "27/160, train_loss: 0.3097\n",
      "28/160, train_loss: 0.3947\n",
      "29/160, train_loss: 0.2379\n",
      "30/160, train_loss: 0.2484\n",
      "31/160, train_loss: 0.2352\n",
      "32/160, train_loss: 0.3438\n",
      "33/160, train_loss: 0.3758\n",
      "34/160, train_loss: 0.2700\n",
      "35/160, train_loss: 0.2348\n",
      "36/160, train_loss: 0.2045\n",
      "37/160, train_loss: 0.2307\n",
      "38/160, train_loss: 0.2858\n",
      "39/160, train_loss: 0.5904\n",
      "40/160, train_loss: 0.1840\n",
      "41/160, train_loss: 0.2885\n",
      "42/160, train_loss: 0.2251\n",
      "43/160, train_loss: 0.3332\n",
      "44/160, train_loss: 0.2369\n",
      "45/160, train_loss: 0.2530\n",
      "46/160, train_loss: 0.2207\n",
      "47/160, train_loss: 0.3557\n",
      "48/160, train_loss: 0.2240\n",
      "49/160, train_loss: 0.5471\n",
      "50/160, train_loss: 0.3159\n",
      "51/160, train_loss: 0.2921\n",
      "52/160, train_loss: 0.2246\n",
      "53/160, train_loss: 0.2552\n",
      "54/160, train_loss: 0.3598\n",
      "55/160, train_loss: 0.3656\n",
      "56/160, train_loss: 0.3183\n",
      "57/160, train_loss: 0.2906\n",
      "58/160, train_loss: 0.1780\n",
      "59/160, train_loss: 0.2445\n",
      "60/160, train_loss: 0.2742\n",
      "61/160, train_loss: 0.2803\n",
      "62/160, train_loss: 0.3006\n",
      "63/160, train_loss: 0.2093\n",
      "64/160, train_loss: 0.1815\n",
      "65/160, train_loss: 0.3113\n",
      "66/160, train_loss: 0.3121\n",
      "67/160, train_loss: 0.2070\n",
      "68/160, train_loss: 0.1874\n",
      "69/160, train_loss: 0.3829\n",
      "70/160, train_loss: 0.2393\n",
      "71/160, train_loss: 0.4305\n",
      "72/160, train_loss: 0.2579\n",
      "73/160, train_loss: 0.2953\n",
      "74/160, train_loss: 0.3622\n",
      "75/160, train_loss: 0.2646\n",
      "76/160, train_loss: 0.2426\n",
      "77/160, train_loss: 0.5468\n",
      "78/160, train_loss: 0.3398\n",
      "79/160, train_loss: 0.2925\n",
      "80/160, train_loss: 0.2941\n",
      "81/160, train_loss: 0.3923\n",
      "82/160, train_loss: 0.2728\n",
      "83/160, train_loss: 0.2667\n",
      "84/160, train_loss: 0.2965\n",
      "85/160, train_loss: 0.3144\n",
      "86/160, train_loss: 0.2114\n",
      "87/160, train_loss: 0.3861\n",
      "88/160, train_loss: 0.1950\n",
      "89/160, train_loss: 0.3340\n",
      "90/160, train_loss: 0.3879\n",
      "91/160, train_loss: 0.4278\n",
      "92/160, train_loss: 0.2685\n",
      "93/160, train_loss: 0.2498\n",
      "94/160, train_loss: 0.3384\n",
      "95/160, train_loss: 0.1956\n",
      "96/160, train_loss: 0.2774\n",
      "97/160, train_loss: 0.2609\n",
      "98/160, train_loss: 0.1926\n",
      "99/160, train_loss: 0.2249\n",
      "100/160, train_loss: 0.2833\n",
      "101/160, train_loss: 0.2532\n",
      "102/160, train_loss: 0.4203\n",
      "103/160, train_loss: 0.5369\n",
      "104/160, train_loss: 0.3056\n",
      "105/160, train_loss: 0.2410\n",
      "106/160, train_loss: 0.3858\n",
      "107/160, train_loss: 0.2359\n",
      "108/160, train_loss: 0.3461\n",
      "109/160, train_loss: 0.3487\n",
      "110/160, train_loss: 0.3076\n",
      "111/160, train_loss: 0.4141\n",
      "112/160, train_loss: 0.3242\n",
      "113/160, train_loss: 0.3209\n",
      "114/160, train_loss: 0.3196\n",
      "115/160, train_loss: 0.2741\n",
      "116/160, train_loss: 0.2139\n",
      "117/160, train_loss: 0.1975\n",
      "118/160, train_loss: 0.2170\n",
      "119/160, train_loss: 0.2725\n",
      "120/160, train_loss: 0.2211\n",
      "121/160, train_loss: 0.3336\n",
      "122/160, train_loss: 0.3200\n",
      "123/160, train_loss: 0.2402\n",
      "124/160, train_loss: 0.2521\n",
      "125/160, train_loss: 0.4862\n",
      "126/160, train_loss: 0.2825\n",
      "127/160, train_loss: 0.3219\n",
      "128/160, train_loss: 0.3178\n",
      "129/160, train_loss: 0.3022\n",
      "130/160, train_loss: 0.2551\n",
      "131/160, train_loss: 0.3599\n",
      "132/160, train_loss: 0.3299\n",
      "133/160, train_loss: 0.3358\n",
      "134/160, train_loss: 0.4037\n",
      "135/160, train_loss: 0.3930\n",
      "136/160, train_loss: 0.2251\n",
      "137/160, train_loss: 0.4155\n",
      "138/160, train_loss: 0.3912\n",
      "139/160, train_loss: 0.2915\n",
      "140/160, train_loss: 0.3515\n",
      "141/160, train_loss: 0.2809\n",
      "142/160, train_loss: 0.3114\n",
      "143/160, train_loss: 0.3200\n",
      "144/160, train_loss: 0.2279\n",
      "145/160, train_loss: 0.2532\n",
      "146/160, train_loss: 0.2875\n",
      "147/160, train_loss: 0.2735\n",
      "148/160, train_loss: 0.3088\n",
      "149/160, train_loss: 0.3811\n",
      "150/160, train_loss: 0.2892\n",
      "151/160, train_loss: 0.3517\n",
      "152/160, train_loss: 0.3838\n",
      "153/160, train_loss: 0.2529\n",
      "154/160, train_loss: 0.3046\n",
      "155/160, train_loss: 0.2969\n",
      "156/160, train_loss: 0.2267\n",
      "157/160, train_loss: 0.2462\n",
      "158/160, train_loss: 0.2872\n",
      "159/160, train_loss: 0.4072\n",
      "160/160, train_loss: 0.3376\n",
      "Epoch 8/10 159/160 loss: 0.3026 time 73.04s\n",
      "0/40 dice: 0.7819\n",
      "1/40 dice: 0.6926\n",
      "2/40 dice: 0.6567\n",
      "3/40 dice: 0.7341\n",
      "4/40 dice: 0.6713\n",
      "5/40 dice: 0.7527\n",
      "6/40 dice: 0.7526\n",
      "7/40 dice: 0.7012\n",
      "8/40 dice: 0.7079\n",
      "9/40 dice: 0.7840\n",
      "10/40 dice: 0.6654\n",
      "11/40 dice: 0.7707\n",
      "12/40 dice: 0.5316\n",
      "13/40 dice: 0.6395\n",
      "14/40 dice: 0.6004\n",
      "15/40 dice: 0.7055\n",
      "16/40 dice: 0.7357\n",
      "17/40 dice: 0.6946\n",
      "18/40 dice: 0.7138\n",
      "19/40 dice: 0.6939\n",
      "20/40 dice: 0.6610\n",
      "21/40 dice: 0.6511\n",
      "22/40 dice: 0.6215\n",
      "23/40 dice: 0.7140\n",
      "24/40 dice: 0.7502\n",
      "25/40 dice: 0.7042\n",
      "26/40 dice: 0.7613\n",
      "27/40 dice: 0.7863\n",
      "28/40 dice: 0.7456\n",
      "29/40 dice: 0.7015\n",
      "30/40 dice: 0.7248\n",
      "31/40 dice: 0.6625\n",
      "32/40 dice: 0.5988\n",
      "33/40 dice: 0.7293\n",
      "34/40 dice: 0.6622\n",
      "35/40 dice: 0.6799\n",
      "36/40 dice: 0.6390\n",
      "37/40 dice: 0.6642\n",
      "38/40 dice: 0.7677\n",
      "39/40 dice: 0.6797\n",
      "current epoch: 9 current mean dice: 0.6973 best mean dice: 0.7093 at epoch: 8\n",
      "----------\n",
      "epoch 10/10\n",
      "1/160, train_loss: 0.3124\n",
      "2/160, train_loss: 0.1615\n",
      "3/160, train_loss: 0.1683\n",
      "4/160, train_loss: 0.2482\n",
      "5/160, train_loss: 0.3244\n",
      "6/160, train_loss: 0.1913\n",
      "7/160, train_loss: 0.3267\n",
      "8/160, train_loss: 0.3040\n",
      "9/160, train_loss: 0.3444\n",
      "10/160, train_loss: 0.3295\n",
      "11/160, train_loss: 0.2725\n",
      "12/160, train_loss: 0.3201\n",
      "13/160, train_loss: 0.2030\n",
      "14/160, train_loss: 0.2620\n",
      "15/160, train_loss: 0.4055\n",
      "16/160, train_loss: 0.3877\n",
      "17/160, train_loss: 0.3666\n",
      "18/160, train_loss: 0.2590\n",
      "19/160, train_loss: 0.2948\n",
      "20/160, train_loss: 0.3384\n",
      "21/160, train_loss: 0.3274\n",
      "22/160, train_loss: 0.4252\n",
      "23/160, train_loss: 0.3901\n",
      "24/160, train_loss: 0.2980\n",
      "25/160, train_loss: 0.2600\n",
      "26/160, train_loss: 0.2277\n",
      "27/160, train_loss: 0.2553\n",
      "28/160, train_loss: 0.3662\n",
      "29/160, train_loss: 0.3138\n",
      "30/160, train_loss: 0.2646\n",
      "31/160, train_loss: 0.3634\n",
      "32/160, train_loss: 0.4946\n",
      "33/160, train_loss: 0.2707\n",
      "34/160, train_loss: 0.4133\n",
      "35/160, train_loss: 0.3906\n",
      "36/160, train_loss: 0.2116\n",
      "37/160, train_loss: 0.3021\n",
      "38/160, train_loss: 0.2165\n",
      "39/160, train_loss: 0.2580\n",
      "40/160, train_loss: 0.3070\n",
      "41/160, train_loss: 0.3408\n",
      "42/160, train_loss: 0.3432\n",
      "43/160, train_loss: 0.3008\n",
      "44/160, train_loss: 0.3630\n",
      "45/160, train_loss: 0.2656\n",
      "46/160, train_loss: 0.3150\n",
      "47/160, train_loss: 0.4449\n",
      "48/160, train_loss: 0.2642\n",
      "49/160, train_loss: 0.2869\n",
      "50/160, train_loss: 0.2290\n",
      "51/160, train_loss: 0.4069\n",
      "52/160, train_loss: 0.3346\n",
      "53/160, train_loss: 0.2570\n",
      "54/160, train_loss: 0.2387\n",
      "55/160, train_loss: 0.2037\n",
      "56/160, train_loss: 0.4010\n",
      "57/160, train_loss: 0.2455\n",
      "58/160, train_loss: 0.3849\n",
      "59/160, train_loss: 0.3263\n",
      "60/160, train_loss: 0.2439\n",
      "61/160, train_loss: 0.2045\n",
      "62/160, train_loss: 0.2384\n",
      "63/160, train_loss: 0.1869\n",
      "64/160, train_loss: 0.2104\n",
      "65/160, train_loss: 0.2038\n",
      "66/160, train_loss: 0.2813\n",
      "67/160, train_loss: 0.3820\n",
      "68/160, train_loss: 0.4862\n",
      "69/160, train_loss: 0.4017\n",
      "70/160, train_loss: 0.2483\n",
      "71/160, train_loss: 0.2515\n",
      "72/160, train_loss: 0.3458\n",
      "73/160, train_loss: 0.2466\n",
      "74/160, train_loss: 0.2556\n",
      "75/160, train_loss: 0.3820\n",
      "76/160, train_loss: 0.3428\n",
      "77/160, train_loss: 0.2891\n",
      "78/160, train_loss: 0.2585\n",
      "79/160, train_loss: 0.3691\n",
      "80/160, train_loss: 0.2448\n",
      "81/160, train_loss: 0.3262\n",
      "82/160, train_loss: 0.2984\n",
      "83/160, train_loss: 0.2910\n",
      "84/160, train_loss: 0.2557\n",
      "85/160, train_loss: 0.3736\n",
      "86/160, train_loss: 0.2460\n",
      "87/160, train_loss: 0.2984\n",
      "88/160, train_loss: 0.2532\n",
      "89/160, train_loss: 0.3582\n",
      "90/160, train_loss: 0.2099\n",
      "91/160, train_loss: 0.1969\n",
      "92/160, train_loss: 0.2659\n",
      "93/160, train_loss: 0.3827\n",
      "94/160, train_loss: 0.2119\n",
      "95/160, train_loss: 0.4179\n",
      "96/160, train_loss: 0.2089\n",
      "97/160, train_loss: 0.2577\n",
      "98/160, train_loss: 0.2639\n",
      "99/160, train_loss: 0.2349\n",
      "100/160, train_loss: 0.3734\n",
      "101/160, train_loss: 0.2293\n",
      "102/160, train_loss: 0.2761\n",
      "103/160, train_loss: 0.3573\n",
      "104/160, train_loss: 0.2126\n",
      "105/160, train_loss: 0.2569\n",
      "106/160, train_loss: 0.3507\n",
      "107/160, train_loss: 0.2705\n",
      "108/160, train_loss: 0.2589\n",
      "109/160, train_loss: 0.2906\n",
      "110/160, train_loss: 0.4749\n",
      "111/160, train_loss: 0.2552\n",
      "112/160, train_loss: 0.4427\n",
      "113/160, train_loss: 0.2550\n",
      "114/160, train_loss: 0.3884\n",
      "115/160, train_loss: 0.2037\n",
      "116/160, train_loss: 0.4148\n",
      "117/160, train_loss: 0.2506\n",
      "118/160, train_loss: 0.3735\n",
      "119/160, train_loss: 0.2438\n",
      "120/160, train_loss: 0.1496\n",
      "121/160, train_loss: 0.2288\n",
      "122/160, train_loss: 0.3559\n",
      "123/160, train_loss: 0.2551\n",
      "124/160, train_loss: 0.2380\n",
      "125/160, train_loss: 0.3511\n",
      "126/160, train_loss: 0.3818\n",
      "127/160, train_loss: 0.2374\n",
      "128/160, train_loss: 0.2846\n",
      "129/160, train_loss: 0.3138\n",
      "130/160, train_loss: 0.2454\n",
      "131/160, train_loss: 0.3124\n",
      "132/160, train_loss: 0.2627\n",
      "133/160, train_loss: 0.4282\n",
      "134/160, train_loss: 0.3481\n",
      "135/160, train_loss: 0.2666\n",
      "136/160, train_loss: 0.1950\n",
      "137/160, train_loss: 0.2300\n",
      "138/160, train_loss: 0.3299\n",
      "139/160, train_loss: 0.3109\n",
      "140/160, train_loss: 0.2241\n",
      "141/160, train_loss: 0.2924\n",
      "142/160, train_loss: 0.3505\n",
      "143/160, train_loss: 0.3023\n",
      "144/160, train_loss: 0.2448\n",
      "145/160, train_loss: 0.1688\n",
      "146/160, train_loss: 0.2986\n",
      "147/160, train_loss: 0.2137\n",
      "148/160, train_loss: 0.2051\n",
      "149/160, train_loss: 0.2488\n",
      "150/160, train_loss: 0.2597\n",
      "151/160, train_loss: 0.2808\n",
      "152/160, train_loss: 0.3416\n",
      "153/160, train_loss: 0.3945\n",
      "154/160, train_loss: 0.2075\n",
      "155/160, train_loss: 0.2982\n",
      "156/160, train_loss: 0.3528\n",
      "157/160, train_loss: 0.3648\n",
      "158/160, train_loss: 0.2586\n",
      "159/160, train_loss: 0.2685\n",
      "160/160, train_loss: 0.2572\n",
      "Epoch 9/10 159/160 loss: 0.2956 time 72.50s\n",
      "0/40 dice: 0.7794\n",
      "1/40 dice: 0.7225\n",
      "2/40 dice: 0.6884\n",
      "3/40 dice: 0.7568\n",
      "4/40 dice: 0.7292\n",
      "5/40 dice: 0.7939\n",
      "6/40 dice: 0.7888\n",
      "7/40 dice: 0.7408\n",
      "8/40 dice: 0.7495\n",
      "9/40 dice: 0.7895\n",
      "10/40 dice: 0.7079\n",
      "11/40 dice: 0.7998\n",
      "12/40 dice: 0.6180\n",
      "13/40 dice: 0.7084\n",
      "14/40 dice: 0.6665\n",
      "15/40 dice: 0.7325\n",
      "16/40 dice: 0.7456\n",
      "17/40 dice: 0.6971\n",
      "18/40 dice: 0.7268\n",
      "19/40 dice: 0.6889\n",
      "20/40 dice: 0.7467\n",
      "21/40 dice: 0.6357\n",
      "22/40 dice: 0.6832\n",
      "23/40 dice: 0.7266\n",
      "24/40 dice: 0.7772\n",
      "25/40 dice: 0.7467\n",
      "26/40 dice: 0.7787\n",
      "27/40 dice: 0.7670\n",
      "28/40 dice: 0.7495\n",
      "29/40 dice: 0.7183\n",
      "30/40 dice: 0.7481\n",
      "31/40 dice: 0.6800\n",
      "32/40 dice: 0.6225\n",
      "33/40 dice: 0.7357\n",
      "34/40 dice: 0.7131\n",
      "35/40 dice: 0.6839\n",
      "36/40 dice: 0.6993\n",
      "37/40 dice: 0.7256\n",
      "38/40 dice: 0.7807\n",
      "39/40 dice: 0.6990\n",
      "saved new best metric model\n",
      "current epoch: 10 current mean dice: 0.7262 best mean dice: 0.7262 at epoch: 10\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    start_time = time.time()\n",
    "    for idx, batch_data in enumerate(train_loader):\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[\"image\"].to(device), batch_data[\"mask\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    # print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    print(\n",
    "            \"Epoch {}/{} {}/{}\".format(epoch, max_epochs, idx, len(train_loader)),\n",
    "            \"loss: {:.4f}\".format(epoch_loss),\n",
    "            \"time {:.2f}s\".format(time.time() - start_time),\n",
    "        )\n",
    "    start_time = time.time()\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_dices = []\n",
    "            for idx, val_data in enumerate(val_loader):\n",
    "                val_inputs, val_labels = val_data[\"image\"].to(device), val_data[\"mask\"].to(device)\n",
    "                val_outputs = model_inferer(val_inputs)\n",
    "                dice_val = dice(val_outputs, val_labels)\n",
    "                epoch_dices.append(dice_val)\n",
    "                \n",
    "                print(f\"{idx}/{len(val_ds)} dice: {dice_val:.4f}\")\n",
    "                \n",
    "            dice_epoch = torch.stack(epoch_dices).mean()\n",
    "\n",
    "            metric_values.append(dice_epoch)\n",
    "            if dice_epoch > best_metric:\n",
    "                best_metric = dice_epoch\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"best_metric_model.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {dice_epoch:.4f} \"\n",
    "                f\"best mean dice: {best_metric:.4f} at epoch: {best_metric_epoch}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_metrics = np.array([tensor.cpu().numpy() for tensor in metric_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot for train loss\n",
    "ax1.plot(range(max_epochs), epoch_loss_values, \"r\", label=\"train loss\")\n",
    "ax1.set_xlabel(\"epoch\", color=\"k\")\n",
    "ax1.set_ylabel(\"Loss\", color=\"r\")\n",
    "ax1.legend(loc=\"upper left\")\n",
    "\n",
    "# Plot for validation mean dice\n",
    "ax2.plot(range(max_epochs), numpy_metrics, \"b\", label=\"val mean dice\")\n",
    "ax2.set_xlabel(\"epoch\", color=\"k\")\n",
    "ax2.set_ylabel(\"Dice\", color=\"b\")\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lumen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
