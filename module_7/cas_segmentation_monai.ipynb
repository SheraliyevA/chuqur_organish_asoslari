{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai import transforms\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Activations,\n",
    ")\n",
    "\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.utils.enums import MetricReduction\n",
    "from monai.networks.nets import SwinUNETR, SegResNet, UNet\n",
    "from monai import data\n",
    "from monai.data import decollate_batch\n",
    "from functools import partial\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datafold_read(datalist, basedir, fold=0, key=\"training\"):\n",
    "    with open(datalist) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    json_data = json_data[key]\n",
    "\n",
    "    for d in json_data:\n",
    "        for k in d:\n",
    "            if isinstance(d[k], list):\n",
    "                d[k] = [os.path.join(basedir, iv) for iv in d[k]]\n",
    "            elif isinstance(d[k], str):\n",
    "                d[k] = os.path.join(basedir, d[k]) if len(d[k]) > 0 else d[k]\n",
    "\n",
    "    tr = []\n",
    "    val = []\n",
    "    for d in json_data:\n",
    "        if \"fold\" in d and d[\"fold\"] == fold:\n",
    "            val.append(d)\n",
    "        else:\n",
    "            tr.append(d)\n",
    "\n",
    "    return tr, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/ikboljon.sobirov/data/fs1_research/Ikboljon.Sobirov/imagecas/imagecas/resampled_space/'\n",
    "json_file = '/home/ikboljon.sobirov/data/nas/ikboljon.sobirov/image_cas/chuqur_organish_asoslari/module_6/train_data.json'\n",
    "fold = 1\n",
    "roi = (96, 96, 96)\n",
    "batch_size = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, validation_files = datafold_read(datalist=json_file, basedir=data_dir, fold=fold)\n",
    "# 200, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_norm = (img - mean)/std\n",
    "# min_max = (img - min)/(max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image_path\", \"mask_path\"], ensure_channel_first=True),\n",
    "        transforms.SpatialPadd(keys=[\"image_path\", \"mask_path\"], spatial_size=roi),\n",
    "        transforms.RandCropByPosNegLabeld(keys=[\"image_path\", \"mask_path\"], \n",
    "                                        label_key=\"mask_path\",\n",
    "                                        spatial_size=roi,\n",
    "                                        num_samples=4,\n",
    "                                        image_key=\"image_path\",),\n",
    "        # transforms.CropForegroundd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     source_key=\"image\",\n",
    "        #     k_divisible=[roi[0], roi[1], roi[2]],\n",
    "        # ),\n",
    "        # transforms.RandSpatialCropd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     roi_size=[roi[0], roi[1], roi[2]],\n",
    "        #     random_size=False,\n",
    "        # ),\n",
    "        # transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        # transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        # transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        # transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        # transforms.RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "        # transforms.RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "    ]\n",
    ")\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image_path\", \"mask_path\"], ensure_channel_first=True),\n",
    "        transforms.SpatialPadd(keys=[\"image_path\", \"mask_path\"], spatial_size=roi),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_ds = data.Dataset(data=train_files, transform=train_transform)\n",
    "\n",
    "train_loader = data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_ds = data.Dataset(data=validation_files, transform=val_transform)\n",
    "val_loader = data.DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 96, 96, 96])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['mask_path'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9f1ca4be50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a['mask_path'].cpu().detach()[0, 0, :, :, 25], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegResNet(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=False, sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=False, reduction=MetricReduction.MEAN)\n",
    "\n",
    "max_epochs = 100\n",
    "val_interval = 1\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "# post_pred = AsDiscrete(argmax=True, to_onehot=True, n_classes=2)\n",
    "# post_label = AsDiscrete(to_onehot=True, n_classes=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[\"image_path\"].to(device), batch_data[\"mask_path\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            metric_sum = 0.0\n",
    "            metric_count = 0\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = val_data[\"image_path\"].to(device), val_data[\"mask_path\"].to(device)\n",
    "                val_outputs = model(val_inputs)\n",
    "                value = dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                metric_count += len(value)\n",
    "                metric_sum += value.sum().item()\n",
    "            metric = metric_sum / metric_count\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"best_metric_model.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f} \"\n",
    "                f\"best mean dice: {best_metric:.4f} at epoch: {best_metric_epoch}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(range(max_epochs), epoch_loss_values, \"r\", label=\"train loss\")\n",
    "ax1.set_xlabel(\"epoch\", color=\"k\")\n",
    "ax1.set_ylabel(\"Loss\", color=\"r\")\n",
    "ax1.legend(loc=\"upper left\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(max_epochs), metric_values, \"b\", label=\"val mean dice\")\n",
    "ax2.set_ylabel(\"Dice\", color=\"b\")\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lumen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
